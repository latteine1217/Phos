"""
Phos 0.1.3 - Film Simulation Based on Computational Optics

"No LUTs, we calculate LUX."

ä½ è¯´çš„å¯¹ï¼Œä½†æ˜¯ Phos. æ˜¯åŸºäºã€Œè®¡ç®—å…‰å­¦ã€æ¦‚å¿µçš„èƒ¶ç‰‡æ¨¡æ‹Ÿã€‚
é€šè¿‡è®¡ç®—å…‰åœ¨åº•ç‰‡ä¸Šçš„è¡Œä¸ºï¼Œå¤ç°è‡ªç„¶ã€æŸ”ç¾ã€ç«‹ä½“çš„èƒ¶ç‰‡è´¨æ„Ÿã€‚

Version: 0.1.3 (Optimized)
Release Notes: See V0.1.3_RELEASE.md for details
"""

import streamlit as st

# è®¾ç½®é¡µé¢é…ç½® 
st.set_page_config(
    page_title="Phos. èƒ¶ç‰‡æ¨¡æ‹Ÿ",
    page_icon="ğŸï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

import cv2
import numpy as np
import time
from PIL import Image
import io
from typing import Optional, Tuple
from functools import lru_cache

# å°å…¥èƒ¶ç‰‡æ¨¡å‹
from film_models import (
    get_film_profile, 
    FilmProfile, 
    EmulsionLayer,
    STANDARD_IMAGE_SIZE,
    SENSITIVITY_MIN,
    SENSITIVITY_MAX,
    SENSITIVITY_SCALE,
    SENSITIVITY_BASE,
    BLOOM_STRENGTH_FACTOR,
    BLOOM_RADIUS_FACTOR,
    BLOOM_RADIUS_MIN,
    BLOOM_RADIUS_MAX,
    BASE_DIFFUSION_FACTOR,
    GRAIN_WEIGHT_MIN,
    GRAIN_WEIGHT_MAX,
    GRAIN_SENS_MIN,
    GRAIN_SENS_MAX,
    GRAIN_BLUR_KERNEL,
    GRAIN_BLUR_SIGMA,
    REINHARD_GAMMA_ADJUSTMENT,
    FILMIC_EXPOSURE_SCALE
)


# ==================== å¿«å–è£é£¾å™¨ ====================

@st.cache_resource
def get_cached_film_profile(film_type: str) -> FilmProfile:
    """
    å¿«å–èƒ¶ç‰‡é…ç½®ï¼Œé¿å…é‡è¤‡å‰µå»º
    
    Args:
        film_type: èƒ¶ç‰‡é¡å‹
        
    Returns:
        FilmProfile: å¿«å–çš„èƒ¶ç‰‡é…ç½®
    """
    return get_film_profile(film_type)


# ==================== åœ–åƒé è™•ç† ====================

def standardize(image: np.ndarray) -> np.ndarray:
    """
    æ¨™æº–åŒ–åœ–åƒå°ºå¯¸
    
    å°‡åœ–åƒçš„çŸ­é‚Šèª¿æ•´ç‚ºæ¨™æº–å°ºå¯¸ï¼ˆ3000pxï¼‰ï¼Œä¿æŒå¯¬é«˜æ¯”
    
    Args:
        image: è¼¸å…¥åœ–åƒ (BGR æ ¼å¼)
        
    Returns:
        èª¿æ•´å¾Œçš„åœ–åƒ
    """
    height, width = image.shape[:2]
    
    # ç¢ºå®šç¸®æ”¾æ¯”ä¾‹
    if height < width:
        # ç«–åœ– - é«˜åº¦ç‚ºçŸ­é‚Š
        scale_factor = STANDARD_IMAGE_SIZE / height
        new_height = STANDARD_IMAGE_SIZE
        new_width = int(width * scale_factor)
    else:
        # æ©«åœ– - å¯¬åº¦ç‚ºçŸ­é‚Š
        scale_factor = STANDARD_IMAGE_SIZE / width
        new_width = STANDARD_IMAGE_SIZE
        new_height = int(height * scale_factor)
    
    # ç¢ºä¿æ–°å°ºå¯¸ç‚ºå¶æ•¸ï¼ˆé¿å…æŸäº›è™•ç†å•é¡Œï¼‰
    new_width = new_width + 1 if new_width % 2 != 0 else new_width
    new_height = new_height + 1 if new_height % 2 != 0 else new_height
    
    # é¸æ“‡é©ç•¶çš„æ’å€¼æ–¹æ³•
    interpolation = cv2.INTER_AREA if scale_factor < 1 else cv2.INTER_LANCZOS4
    resized_image = cv2.resize(image, (new_width, new_height), interpolation=interpolation)
    
    return resized_image


# ==================== å…‰åº¦è¨ˆç®— ====================

def luminance(image: np.ndarray, film: FilmProfile) -> Tuple[Optional[np.ndarray], Optional[np.ndarray], Optional[np.ndarray], np.ndarray]:
    """
    è¨ˆç®—äº®åº¦åœ–åƒï¼Œæ¨¡æ“¬èƒ¶ç‰‡æ„Ÿå…‰å±¤çš„å…‰è­œéŸ¿æ‡‰
    
    é€™å€‹å‡½æ•¸æ¨¡æ“¬äº†å…‰åœ¨èƒ¶ç‰‡ä¸åŒæ„Ÿå…‰å±¤ä¸­çš„å¸æ”¶éç¨‹ã€‚
    æ¯å€‹æ„Ÿå…‰å±¤å°ä¸åŒæ³¢é•·çš„å…‰æœ‰ä¸åŒçš„æ•æ„Ÿåº¦ã€‚
    
    Args:
        image: è¼¸å…¥åœ–åƒ (BGR æ ¼å¼ï¼Œ0-255)
        film: èƒ¶ç‰‡é…ç½®å°è±¡
        
    Returns:
        (lux_r, lux_g, lux_b, lux_total): å„é€šé“çš„å…‰åº¦éŸ¿æ‡‰ (0-1 ç¯„åœ)
            - å½©è‰²èƒ¶ç‰‡: lux_r/g/b ç‚ºå„å±¤éŸ¿æ‡‰ï¼Œlux_total ç‚ºå…¨è‰²å±¤
            - é»‘ç™½èƒ¶ç‰‡: åƒ… lux_total æœ‰å€¼ï¼Œå…¶é¤˜ç‚º None
    """
    # åˆ†é›¢ RGB é€šé“
    b, g, r = cv2.split(image)
    
    # è½‰æ›ç‚ºæµ®é»æ•¸ (0-1 ç¯„åœ)
    r_float = r.astype(np.float32) / 255.0
    g_float = g.astype(np.float32) / 255.0
    b_float = b.astype(np.float32) / 255.0
    
    # ç²å–å…‰è­œéŸ¿æ‡‰ä¿‚æ•¸
    r_r, r_g, r_b, g_r, g_g, g_b, b_r, b_g, b_b, t_r, t_g, t_b = film.get_spectral_response()
    
    # æ¨¡æ“¬ä¸åŒä¹³åŠ‘å±¤çš„å¸æ”¶ç‰¹æ€§ï¼ˆå…‰è­œæ•æ„Ÿåº¦çš„ç·šæ€§çµ„åˆï¼‰
    if film.color_type == "color":
        lux_r = r_r * r_float + r_g * g_float + r_b * b_float
        lux_g = g_r * r_float + g_g * g_float + g_b * b_float
        lux_b = b_r * r_float + b_g * g_float + b_b * b_float
        lux_total = t_r * r_float + t_g * g_float + t_b * b_float
    else:
        lux_total = t_r * r_float + t_g * g_float + t_b * b_float
        lux_r = None
        lux_g = None
        lux_b = None

    return lux_r, lux_g, lux_b, lux_total


def average_luminance(lux_total: np.ndarray) -> float:
    """
    è¨ˆç®—åœ–åƒçš„å¹³å‡äº®åº¦
    
    Args:
        lux_total: å…¨è‰²é€šé“çš„å…‰åº¦æ•¸æ“š
        
    Returns:
        å¹³å‡äº®åº¦å€¼ (0-1 ç¯„åœ)
    """
    avg_lux = np.mean(lux_total)
    return np.clip(avg_lux, 0, 1)


# ==================== èƒ¶ç‰‡é¡†ç²’æ•ˆæœ ====================

def generate_grain_for_channel(lux_channel: np.ndarray, sens: float) -> np.ndarray:
    """
    ç‚ºå–®å€‹é€šé“ç”Ÿæˆèƒ¶ç‰‡é¡†ç²’å™ªè²
    
    èƒ¶ç‰‡é¡†ç²’æ˜¯ç”±æ–¼éŠ€é¹½æ™¶é«”çš„éš¨æ©Ÿåˆ†å¸ƒç”¢ç”Ÿçš„ã€‚
    é€™å€‹å‡½æ•¸ä½¿ç”¨åŠ æ¬Šéš¨æ©Ÿå™ªè²ä¾†æ¨¡æ“¬é€™ç¨®æ•ˆæœã€‚
    
    Args:
        lux_channel: å…‰åº¦é€šé“æ•¸æ“š (0-1 ç¯„åœ)
        sens: æ•æ„Ÿåº¦åƒæ•¸
        
    Returns:
        åŠ æ¬Šå™ªè² (-1 åˆ° 1 ç¯„åœ)
    """
    # å‰µå»ºæ­£è² å™ªè²ï¼ˆä½¿ç”¨å¹³æ–¹æ­£æ…‹åˆ†ä½ˆç”¢ç”Ÿæ›´è‡ªç„¶çš„é¡†ç²’ï¼‰
    noise = np.random.normal(0, 1, lux_channel.shape).astype(np.float32)
    noise = noise ** 2
    noise = noise * np.random.choice([-1, 1], lux_channel.shape)
    
    # å‰µå»ºæ¬Šé‡åœ–ï¼ˆä¸­ç­‰äº®åº¦å€åŸŸæ¬Šé‡æœ€é«˜ï¼Œæ¨¡æ“¬èƒ¶ç‰‡é¡†ç²’åœ¨ä¸­é–“èª¿æœ€æ˜é¡¯çš„ç‰¹æ€§ï¼‰
    weights = (0.5 - np.abs(lux_channel - 0.5)) * 2
    weights = np.clip(weights, GRAIN_WEIGHT_MIN, GRAIN_WEIGHT_MAX)
    
    # æ‡‰ç”¨æ¬Šé‡å’Œæ•æ„Ÿåº¦
    sens_grain = np.clip(sens, GRAIN_SENS_MIN, GRAIN_SENS_MAX)
    weighted_noise = noise * weights * sens_grain
    
    # æ·»åŠ è¼•å¾®æ¨¡ç³Šä½¿é¡†ç²’æ›´æŸ”å’Œ
    weighted_noise = cv2.GaussianBlur(weighted_noise, GRAIN_BLUR_KERNEL, GRAIN_BLUR_SIGMA)
    
    return np.clip(weighted_noise, -1, 1)


def apply_grain(lux_r: Optional[np.ndarray], lux_g: Optional[np.ndarray], 
                lux_b: Optional[np.ndarray], lux_total: np.ndarray, 
                film: FilmProfile, sens: float) -> Tuple[Optional[np.ndarray], Optional[np.ndarray], Optional[np.ndarray], Optional[np.ndarray]]:
    """
    ç”Ÿæˆèƒ¶ç‰‡é¡†ç²’æ•ˆæœ
    
    Args:
        lux_r, lux_g, lux_b: RGB é€šé“çš„å…‰åº¦æ•¸æ“šï¼ˆå½©è‰²èƒ¶ç‰‡ï¼‰
        lux_total: å…¨è‰²é€šé“çš„å…‰åº¦æ•¸æ“š
        film: èƒ¶ç‰‡é…ç½®å°è±¡
        sens: æ•æ„Ÿåº¦åƒæ•¸
        
    Returns:
        (weighted_noise_r, weighted_noise_g, weighted_noise_b, weighted_noise_total): å„é€šé“çš„é¡†ç²’å™ªè²
    """
    if film.color_type == "color" and all([lux_r is not None, lux_g is not None, lux_b is not None]):
        # å½©è‰²èƒ¶ç‰‡ï¼šç‚ºæ¯å€‹é€šé“ç”Ÿæˆç¨ç«‹çš„é¡†ç²’
        weighted_noise_r = generate_grain_for_channel(lux_r, sens)
        weighted_noise_g = generate_grain_for_channel(lux_g, sens)
        weighted_noise_b = generate_grain_for_channel(lux_b, sens)
        weighted_noise_total = None
    else:
        # é»‘ç™½èƒ¶ç‰‡ï¼šåƒ…ç”Ÿæˆå…¨è‰²é€šé“çš„é¡†ç²’
        weighted_noise_total = generate_grain_for_channel(lux_total, sens)
        weighted_noise_r = None
        weighted_noise_g = None
        weighted_noise_b = None
    
    return weighted_noise_r, weighted_noise_g, weighted_noise_b, weighted_noise_total


# ==================== Tone Mapping ====================

def apply_reinhard_to_channel(lux: np.ndarray, gamma: float, color_mode: bool = False) -> np.ndarray:
    """
    å°å–®å€‹é€šé“æ‡‰ç”¨ Reinhard tone mapping
    
    Reinhard tone mapping æ˜¯ä¸€ç¨®å…¨å±€ tone mapping ç®—æ³•ï¼Œ
    ä½¿ç”¨ç°¡å–®çš„å…¬å¼å°‡ HDR æ˜ å°„åˆ° LDRã€‚
    
    Args:
        lux: è¼¸å…¥å…‰åº¦æ•¸æ“š
        gamma: Gamma å€¼
        color_mode: æ˜¯å¦ç‚ºå½©è‰²æ¨¡å¼ï¼ˆå½±éŸ¿ gamma èª¿æ•´ï¼‰
        
    Returns:
        æ˜ å°„å¾Œçš„çµæœ (0-1 ç¯„åœ)
    """
    # Reinhard tone mapping: L' = L * L / (1 + L)
    mapped = lux * (lux / (1.0 + lux))
    
    # æ‡‰ç”¨ gamma æ ¡æ­£
    gamma_adj = REINHARD_GAMMA_ADJUSTMENT if color_mode else 1.0
    mapped = np.power(np.maximum(mapped, 0), gamma_adj / gamma)
    
    return np.clip(mapped, 0, 1)


def apply_reinhard(lux_r: Optional[np.ndarray], lux_g: Optional[np.ndarray], 
                   lux_b: Optional[np.ndarray], lux_total: np.ndarray, 
                   film: FilmProfile) -> Tuple[Optional[np.ndarray], Optional[np.ndarray], Optional[np.ndarray], Optional[np.ndarray]]:
    """
    Reinhard tone mapping ç®—æ³•
    
    Args:
        lux_r, lux_g, lux_b: RGB é€šé“çš„å…‰åº¦æ•¸æ“š
        lux_total: å…¨è‰²é€šé“çš„å…‰åº¦æ•¸æ“š
        film: èƒ¶ç‰‡é…ç½®å°è±¡
        
    Returns:
        (result_r, result_g, result_b, result_total): æ˜ å°„å¾Œçš„å„é€šé“æ•¸æ“š
    """
    gamma = film.tone_params.gamma
    
    if film.color_type == "color" and all([lux_r is not None, lux_g is not None, lux_b is not None]):
        result_r = apply_reinhard_to_channel(lux_r, gamma, color_mode=True)
        result_g = apply_reinhard_to_channel(lux_g, gamma, color_mode=True)
        result_b = apply_reinhard_to_channel(lux_b, gamma, color_mode=True)
        result_total = None
    else:
        result_total = apply_reinhard_to_channel(lux_total, gamma, color_mode=False)
        result_r = None
        result_g = None
        result_b = None

    return result_r, result_g, result_b, result_total


def apply_filmic_to_channel(lux: np.ndarray, film: FilmProfile) -> np.ndarray:
    """
    å°å–®å€‹é€šé“æ‡‰ç”¨ Filmic tone mapping
    
    Filmic tone mapping ä½¿ç”¨åˆ†æ®µæ›²ç·šæ¨¡æ“¬çœŸå¯¦èƒ¶ç‰‡çš„ç‰¹æ€§æ›²ç·šã€‚
    ç›¸æ¯” Reinhardï¼Œå®ƒå°é«˜å…‰å’Œé™°å½±æœ‰æ›´å¥½çš„æ§åˆ¶ã€‚
    
    Args:
        lux: è¼¸å…¥å…‰åº¦æ•¸æ“š
        film: èƒ¶ç‰‡é…ç½®å°è±¡
        
    Returns:
        æ˜ å°„å¾Œçš„çµæœ
        
    Note:
        ç‰¹æ€§æ›²ç·šä¸‰å€‹é—œéµéƒ¨åˆ†ï¼š
        - Shoulder (è‚©éƒ¨): æ§åˆ¶é«˜å…‰éæ¸¡ï¼Œé¿å…é«˜å…‰æº¢å‡º
        - Linear (ç·šæ€§æ®µ): æ§åˆ¶ä¸­é–“èª¿éŸ¿æ‡‰
        - Toe (è¶¾éƒ¨): æ§åˆ¶é™°å½±éæ¸¡ï¼Œä¿ç•™é™°å½±ç´°ç¯€
    """
    # ç¢ºä¿éè² å€¼
    lux = np.maximum(lux, 0)
    
    # æ‡‰ç”¨æ›å…‰å’Œ gamma
    params = film.tone_params
    x = FILMIC_EXPOSURE_SCALE * np.power(lux, params.gamma)
    
    # Filmic curve: åˆ†æ®µæ›²ç·šå…¬å¼
    A, B, C, D, E, F = (
        params.shoulder_strength, 
        params.linear_strength,
        params.linear_angle, 
        params.toe_strength,
        params.toe_numerator, 
        params.toe_denominator
    )
    
    numerator = x * (A * x + C * B) + D * E
    denominator = x * (A * x + B) + D * F
    
    # é¿å…é™¤é›¶
    with np.errstate(divide='ignore', invalid='ignore'):
        result = np.where(
            denominator != 0,
            (numerator / denominator) - E / F,
            0
        )
    
    return result


def apply_filmic(lux_r: Optional[np.ndarray], lux_g: Optional[np.ndarray], 
                 lux_b: Optional[np.ndarray], lux_total: np.ndarray, 
                 film: FilmProfile) -> Tuple[Optional[np.ndarray], Optional[np.ndarray], Optional[np.ndarray], Optional[np.ndarray]]:
    """
    Filmic tone mapping ç®—æ³•
    
    Args:
        lux_r, lux_g, lux_b: RGB é€šé“çš„å…‰åº¦æ•¸æ“š
        lux_total: å…¨è‰²é€šé“çš„å…‰åº¦æ•¸æ“š
        film: èƒ¶ç‰‡é…ç½®å°è±¡
        
    Returns:
        (result_r, result_g, result_b, result_total): æ˜ å°„å¾Œçš„å„é€šé“æ•¸æ“š
    """
    if film.color_type == "color" and all([lux_r is not None, lux_g is not None, lux_b is not None]):
        result_r = apply_filmic_to_channel(lux_r, film)
        result_g = apply_filmic_to_channel(lux_g, film)
        result_b = apply_filmic_to_channel(lux_b, film)
        result_total = None
    else:
        result_total = apply_filmic_to_channel(lux_total, film)
        result_r = None
        result_g = None
        result_b = None
    
    return result_r, result_g, result_b, result_total


# ==================== å…‰å­¸æ“´æ•£æ•ˆæœ ====================

def calculate_bloom_params(avg_lux: float, sens_factor: float) -> Tuple[float, int, float, float]:
    """
    æ ¹æ“šå¹³å‡äº®åº¦è¨ˆç®—å…‰æšˆåƒæ•¸
    
    Args:
        avg_lux: å¹³å‡äº®åº¦
        sens_factor: èƒ¶ç‰‡æ•æ„Ÿä¿‚æ•¸
        
    Returns:
        (sens, rads, strg, base): æ•æ„Ÿåº¦ã€æ“´æ•£åŠå¾‘ã€å…‰æšˆå¼·åº¦ã€åŸºç¤æ“´æ•£
    """
    # æ ¹æ“šå¹³å‡äº®åº¦è¨ˆç®—æ•æ„Ÿåº¦ï¼ˆæš—åœ–æ›´æ•æ„Ÿï¼‰
    sens = float((1.0 - avg_lux) * SENSITIVITY_SCALE + SENSITIVITY_BASE)
    sens = float(np.clip(sens, SENSITIVITY_MIN, SENSITIVITY_MAX))
    
    # è¨ˆç®—å…‰æšˆå¼·åº¦å’Œæ“´æ•£åŠå¾‘
    strg = float(BLOOM_STRENGTH_FACTOR * (sens ** 2) * sens_factor)
    rads = int(BLOOM_RADIUS_FACTOR * (sens ** 2) * sens_factor)
    rads = int(np.clip(rads, BLOOM_RADIUS_MIN, BLOOM_RADIUS_MAX))
    
    # åŸºç¤æ“´æ•£å¼·åº¦
    base = float(BASE_DIFFUSION_FACTOR * sens_factor)
    
    return sens, rads, strg, base


def apply_bloom_to_channel(lux: np.ndarray, sens: float, rads: int, strg: float, base: float, 
                           blur_scale: int, blur_sigma_scale: float) -> np.ndarray:
    """
    å°å–®å€‹é€šé“æ‡‰ç”¨å…‰æšˆæ•ˆæœ
    
    å…‰æšˆï¼ˆHalationï¼‰æ˜¯ç”±æ–¼å…‰åœ¨èƒ¶ç‰‡ä¸­çš„æ•£å°„å’Œåå°„ç”¢ç”Ÿçš„ã€‚
    é«˜å…‰å€åŸŸæœƒç”¢ç”ŸæŸ”å’Œçš„å…‰æšˆï¼Œé€™æ˜¯èƒ¶ç‰‡çš„ç‰¹å¾µä¹‹ä¸€ã€‚
    
    Args:
        lux: å…‰åº¦é€šé“æ•¸æ“š
        sens: æ•æ„Ÿåº¦
        rads: æ“´æ•£åŠå¾‘
        strg: å…‰æšˆå¼·åº¦
        base: åŸºç¤æ“´æ•£å¼·åº¦
        blur_scale: æ¨¡ç³Šæ ¸å¤§å°å€æ•¸
        blur_sigma_scale: æ¨¡ç³Š sigma å€æ•¸
        
    Returns:
        å…‰æšˆæ•ˆæœ
    """
    # å‰µå»ºæ¬Šé‡ï¼ˆé«˜å…‰å€åŸŸæ¬Šé‡æ›´é«˜ï¼‰
    weights = (base + lux ** 2) * sens
    weights = np.clip(weights, 0, 1)
    
    # è¨ˆç®—æ¨¡ç³Šæ ¸å¤§å°ï¼ˆå¿…é ˆç‚ºå¥‡æ•¸ï¼‰
    ksize = rads * blur_scale
    ksize = ksize if ksize % 2 == 1 else ksize + 1
    
    # å‰µå»ºå…‰æšˆå±¤ï¼ˆä½¿ç”¨é«˜æ–¯æ¨¡ç³Šæ¨¡æ“¬å…‰çš„æ“´æ•£ï¼‰
    bloom_layer = cv2.GaussianBlur(lux * weights, (ksize, ksize), sens * blur_sigma_scale)
    
    # æ‡‰ç”¨å…‰æšˆ
    bloom_effect = bloom_layer * weights * strg
    bloom_effect = bloom_effect / (1.0 + bloom_effect)  # é¿å…éæ›
    
    return bloom_effect


def combine_layers_for_channel(bloom: np.ndarray, lux: np.ndarray, layer: EmulsionLayer,
                               grain_r: Optional[np.ndarray], grain_g: Optional[np.ndarray], 
                               grain_b: Optional[np.ndarray], grain_total: float,
                               use_grain: bool) -> np.ndarray:
    """
    çµ„åˆæ•£å°„å…‰ã€ç›´å°„å…‰å’Œé¡†ç²’æ•ˆæœ
    
    Args:
        bloom: å…‰æšˆæ•ˆæœ
        lux: åŸå§‹å…‰åº¦æ•¸æ“š
        layer: æ„Ÿå…‰å±¤åƒæ•¸
        grain_r, grain_g, grain_b: RGB é¡†ç²’å™ªè²
        grain_total: å…¨è‰²é¡†ç²’å¼·åº¦
        use_grain: æ˜¯å¦ä½¿ç”¨é¡†ç²’
        
    Returns:
        çµ„åˆå¾Œçš„å…‰åº¦æ•¸æ“š
    """
    # æ•£å°„å…‰ + ç›´å°„å…‰ï¼ˆéç·šæ€§éŸ¿æ‡‰ï¼‰
    result = bloom * layer.diffuse_light + np.power(lux, layer.response_curve) * layer.direct_light
    
    # æ·»åŠ é¡†ç²’
    if use_grain:
        # å½©è‰²èƒ¶ç‰‡çš„é¡†ç²’æœ‰è‰²å½©ç›¸é—œæ€§
        if grain_r is not None and grain_g is not None and grain_b is not None:
            result += (grain_r * layer.grain_intensity + 
                      grain_g * grain_total + 
                      grain_b * grain_total)
        elif grain_r is not None:
            result += grain_r * layer.grain_intensity
    
    return result


def optical_processing(lux_r: Optional[np.ndarray], lux_g: Optional[np.ndarray], 
                      lux_b: Optional[np.ndarray], lux_total: np.ndarray,
                      film: FilmProfile, grain_style: str, tone_style: str) -> np.ndarray:
    """
    å…‰å­¸è™•ç†ä¸»å‡½æ•¸
    
    é€™æ˜¯æ•´å€‹èƒ¶ç‰‡æ¨¡æ“¬çš„æ ¸å¿ƒï¼ŒåŒ…å«ï¼š
    1. è¨ˆç®—è‡ªé©æ‡‰åƒæ•¸
    2. æ‡‰ç”¨å…‰æšˆæ•ˆæœï¼ˆHalation/Bloomï¼‰
    3. æ‡‰ç”¨é¡†ç²’æ•ˆæœ
    4. çµ„åˆæ•£å°„å…‰å’Œç›´å°„å…‰
    5. Tone mapping
    6. åˆæˆæœ€çµ‚åœ–åƒ
    
    Args:
        lux_r, lux_g, lux_b: RGB é€šé“çš„å…‰åº¦æ•¸æ“š
        lux_total: å…¨è‰²é€šé“çš„å…‰åº¦æ•¸æ“š
        film: èƒ¶ç‰‡é…ç½®å°è±¡
        grain_style: é¡†ç²’é¢¨æ ¼
        tone_style: Tone mapping é¢¨æ ¼
        
    Returns:
        è™•ç†å¾Œçš„åœ–åƒ (0-255 uint8)
    """
    # 1. è¨ˆç®—è‡ªé©æ‡‰åƒæ•¸
    avg_lux = average_luminance(lux_total)
    sens, rads, strg, base = calculate_bloom_params(avg_lux, film.sensitivity_factor)
    
    # 2. æ‡‰ç”¨é¡†ç²’ï¼ˆå¦‚æœéœ€è¦ï¼‰
    use_grain = (grain_style != "ä¸ä½¿ç”¨")
    if use_grain:
        grain_r, grain_g, grain_b, grain_total_noise = apply_grain(
            lux_r, lux_g, lux_b, lux_total, film, sens
        )
    else:
        grain_r = grain_g = grain_b = grain_total_noise = None
    
    # 3. è™•ç†å„é€šé“
    if film.color_type == "color" and all([lux_r is not None, lux_g is not None, lux_b is not None]):
        # å½©è‰²èƒ¶ç‰‡ï¼šè™•ç† RGB ä¸‰å€‹é€šé“
        # ä¸åŒé¡è‰²é€šé“çš„å…‰æšˆç‰¹æ€§ä¸åŒï¼ˆç´…è‰²æ“´æ•£æœ€å»£ï¼Œè—è‰²æœ€çª„ï¼‰
        bloom_r = apply_bloom_to_channel(lux_r, sens, rads, strg, base, blur_scale=3, blur_sigma_scale=55)
        bloom_g = apply_bloom_to_channel(lux_g, sens, rads, strg, base, blur_scale=2, blur_sigma_scale=35)
        bloom_b = apply_bloom_to_channel(lux_b, sens, rads, strg, base, blur_scale=1, blur_sigma_scale=15)
        
        # çµ„åˆå„å±¤
        lux_r_final = combine_layers_for_channel(
            bloom_r, lux_r, film.red_layer, grain_r, grain_g, grain_b, 
            film.panchromatic_layer.grain_intensity, use_grain
        )
        lux_g_final = combine_layers_for_channel(
            bloom_g, lux_g, film.green_layer, grain_r, grain_g, grain_b,
            film.panchromatic_layer.grain_intensity, use_grain
        )
        lux_b_final = combine_layers_for_channel(
            bloom_b, lux_b, film.blue_layer, grain_r, grain_g, grain_b,
            film.panchromatic_layer.grain_intensity, use_grain
        )
        
        # 4. Tone mapping
        if tone_style == "filmic":
            result_r, result_g, result_b, _ = apply_filmic(lux_r_final, lux_g_final, lux_b_final, lux_total, film)
        else:
            result_r, result_g, result_b, _ = apply_reinhard(lux_r_final, lux_g_final, lux_b_final, lux_total, film)
        
        # 5. åˆæˆæœ€çµ‚åœ–åƒ
        combined_r = (result_r * 255).astype(np.uint8)
        combined_g = (result_g * 255).astype(np.uint8)
        combined_b = (result_b * 255).astype(np.uint8)
        final_image = cv2.merge([combined_b, combined_g, combined_r])
        
    else:
        # é»‘ç™½èƒ¶ç‰‡ï¼šåƒ…è™•ç†å…¨è‰²é€šé“
        bloom = apply_bloom_to_channel(lux_total, sens, rads, strg, base, blur_scale=3, blur_sigma_scale=55)
        
        # çµ„åˆå±¤
        if use_grain and grain_total_noise is not None:
            lux_final = (bloom * film.panchromatic_layer.diffuse_light + 
                        np.power(lux_total, film.panchromatic_layer.response_curve) * film.panchromatic_layer.direct_light +
                        grain_total_noise * film.panchromatic_layer.grain_intensity)
        else:
            lux_final = (bloom * film.panchromatic_layer.diffuse_light + 
                        np.power(lux_total, film.panchromatic_layer.response_curve) * film.panchromatic_layer.direct_light)
        
        # Tone mapping
        if tone_style == "filmic":
            _, _, _, result_total = apply_filmic(None, None, None, lux_final, film)
        else:
            _, _, _, result_total = apply_reinhard(None, None, None, lux_final, film)
        
        # åˆæˆæœ€çµ‚åœ–åƒ
        final_image = (result_total * 255).astype(np.uint8)
    
    return final_image


# ==================== ä¸»è™•ç†æµç¨‹ ====================

def adjust_grain_intensity(film: FilmProfile, grain_style: str) -> FilmProfile:
    """
    æ ¹æ“šç”¨æˆ¶é¸æ“‡èª¿æ•´é¡†ç²’å¼·åº¦
    
    Args:
        film: åŸå§‹èƒ¶ç‰‡é…ç½®
        grain_style: é¡†ç²’é¢¨æ ¼é¸æ“‡
        
    Returns:
        èª¿æ•´å¾Œçš„èƒ¶ç‰‡é…ç½®
    """
    # é¡†ç²’å¼·åº¦å€æ•¸
    multipliers = {
        "é»˜èª": 1.0,
        "æŸ”å’Œ": 0.5,
        "è¼ƒç²—": 1.5,
        "ä¸ä½¿ç”¨": 0.0
    }
    
    multiplier = multipliers.get(grain_style, 1.0)
    
    # å‰µå»ºæ–°çš„æ„Ÿå…‰å±¤ï¼ˆä¸ä¿®æ”¹åŸå§‹é…ç½®ï¼‰
    if film.color_type == "color" and film.red_layer and film.green_layer and film.blue_layer:
        from dataclasses import replace
        return replace(
            film,
            red_layer=replace(film.red_layer, grain_intensity=film.red_layer.grain_intensity * multiplier),
            green_layer=replace(film.green_layer, grain_intensity=film.green_layer.grain_intensity * multiplier),
            blue_layer=replace(film.blue_layer, grain_intensity=film.blue_layer.grain_intensity * multiplier),
            panchromatic_layer=replace(film.panchromatic_layer, grain_intensity=film.panchromatic_layer.grain_intensity * multiplier)
        )
    else:
        from dataclasses import replace
        return replace(
            film,
            panchromatic_layer=replace(film.panchromatic_layer, grain_intensity=film.panchromatic_layer.grain_intensity * multiplier)
        )


def process_image(uploaded_image, film_type: str, grain_style: str, tone_style: str) -> Tuple[np.ndarray, float, str]:
    """
    è™•ç†ä¸Šå‚³çš„åœ–åƒ
    
    é€™æ˜¯ä¸»è¦çš„è™•ç†æµç¨‹ï¼Œå”èª¿æ‰€æœ‰æ­¥é©Ÿï¼š
    1. è®€å–åœ–åƒ
    2. ç²å–èƒ¶ç‰‡é…ç½®
    3. æ¨™æº–åŒ–å°ºå¯¸
    4. è¨ˆç®—å…‰åº¦éŸ¿æ‡‰
    5. æ‡‰ç”¨å…‰å­¸æ•ˆæœ
    
    Args:
        uploaded_image: ä¸Šå‚³çš„åœ–åƒæ–‡ä»¶
        film_type: èƒ¶ç‰‡é¡å‹
        grain_style: é¡†ç²’é¢¨æ ¼
        tone_style: Tone mapping é¢¨æ ¼
        
    Returns:
        (è™•ç†å¾Œçš„åœ–åƒ, è™•ç†æ™‚é–“, è¼¸å‡ºæ–‡ä»¶å)
        
    Raises:
        ValueError: åœ–åƒè®€å–å¤±æ•—æˆ–èƒ¶ç‰‡é¡å‹ç„¡æ•ˆ
    """
    start_time = time.time()
    
    try:
        # 1. è®€å–ä¸Šå‚³çš„æ–‡ä»¶
        file_bytes = np.asarray(bytearray(uploaded_image.read()), dtype=np.uint8)
        image = cv2.imdecode(file_bytes, cv2.IMREAD_COLOR)
        
        if image is None:
            raise ValueError("ç„¡æ³•è®€å–åœ–åƒæ–‡ä»¶ï¼Œè«‹ç¢ºä¿ä¸Šå‚³çš„æ˜¯æœ‰æ•ˆçš„åœ–åƒæ ¼å¼")
        
        # 2. ç²å–èƒ¶ç‰‡é…ç½®ï¼ˆä½¿ç”¨å¿«å–ï¼‰
        film = get_cached_film_profile(film_type)
        
        # 3. èª¿æ•´é¡†ç²’å¼·åº¦
        film = adjust_grain_intensity(film, grain_style)
        
        # 4. æ¨™æº–åŒ–åœ–åƒå°ºå¯¸
        image = standardize(image)
        
        # 5. è¨ˆç®—å…‰åº¦éŸ¿æ‡‰
        lux_r, lux_g, lux_b, lux_total = luminance(image, film)
        
        # 6. æ‡‰ç”¨å…‰å­¸è™•ç†
        final_image = optical_processing(lux_r, lux_g, lux_b, lux_total, film, grain_style, tone_style)
        
        # 7. ç”Ÿæˆè¼¸å‡ºæ–‡ä»¶å
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        output_path = f"phos_{film_type.lower()}_{timestamp}.jpg"
        
        process_time = time.time() - start_time
        
        return final_image, process_time, output_path
        
    except ValueError as e:
        raise e
    except Exception as e:
        raise ValueError(f"è™•ç†åœ–åƒæ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")


# ==================== Streamlit ç•Œé¢ ====================

# å‰µå»ºå´é‚Šæ¬„
with st.sidebar:
    st.header("Phos. èƒ¶ç‰‡æ¨¡æ‹Ÿ")
    st.subheader("åŸºäºè®¡ç®—å…‰å­¦çš„èƒ¶ç‰‡æ¨¡æ‹Ÿ")
    st.text("")
    st.text("ver_0.1.3 âš¡ (å„ªåŒ–ç‰ˆ)")
    st.text("")
    st.text("ğŸï¸ èƒ¶ç‰‡è®¾ç½®")
    
    # èƒ¶ç‰‡é¡å‹é¸æ“‡
    film_type = st.selectbox(
        "è«‹é¸æ“‡èƒ¶ç‰‡:",
        ["NC200", "Portra400", "Ektar100", "AS100", "HP5Plus400", "Cinestill800T", "FS200"],
        index=0,
        help='''é¸æ“‡è¦æ¨¡æ“¬çš„èƒ¶ç‰‡é¡å‹:

        === å½©è‰²èƒ¶ç‰‡ ===
        NC200: éˆæ„Ÿä¾†è‡ªå¯Œå£« C200ï¼Œç¶“å…¸å¯Œå£«è‰²èª¿
        Portra400: ğŸ†• äººåƒç‹è€…ï¼Œç´°è†©è†šè‰²ï¼Œä½é¡†ç²’ï¼ˆéˆæ„Ÿä¾†è‡ª Kodak Portra 400ï¼‰
        Ektar100: ğŸ†• é¢¨æ™¯åˆ©å™¨ï¼Œé«˜é£½å’Œï¼Œæ¥µç´°é¡†ç²’ï¼ˆéˆæ„Ÿä¾†è‡ª Kodak Ektar 100ï¼‰
        Cinestill800T: ğŸ†• é›»å½±æ„Ÿï¼Œå¼·å…‰æšˆï¼Œæº«æš–è‰²èª¿ï¼ˆéˆæ„Ÿä¾†è‡ª CineStill 800Tï¼‰

        === é»‘ç™½èƒ¶ç‰‡ ===
        AS100: éˆæ„Ÿä¾†è‡ªå¯Œå£« ACROSï¼Œç°éšç´°è†©ï¼Œé¡†ç²’æŸ”å’Œ
        HP5Plus400: ğŸ†• ç¶“å…¸é»‘ç™½ï¼Œæ˜é¡¯é¡†ç²’ï¼Œé«˜å°æ¯”ï¼ˆéˆæ„Ÿä¾†è‡ª Ilford HP5 Plus 400ï¼‰
        FS200: é«˜å°æ¯”åº¦é»‘ç™½æ­£ç‰‡ï¼ˆåŸç†é©—è­‰æ¨¡å‹ï¼‰
        '''
    )

    grain_style = st.selectbox(
        "èƒ¶ç‰‡é¡†ç²’åº¦ï¼š",
        ["é»˜èª", "æŸ”å’Œ", "è¼ƒç²—", "ä¸ä½¿ç”¨"],
        index=0,
        help="é¸æ“‡èƒ¶ç‰‡çš„é¡†ç²’åº¦",
    )
    
    tone_style = st.selectbox(
        "æ›²ç·šæ˜ å°„ï¼š",
        ["filmic", "reinhard"],
        index=0,
        help='''é¸æ“‡Tone mappingæ–¹å¼:
        
        ç›®å‰ç‰ˆæœ¬ä¸‹Reinhardæ¨¡å‹ä¼¼ä¹è¡¨ç¾å‡ºæ›´å¥½çš„å‹•æ…‹ç¯„åœï¼Œ
        filmicæ¨¡å‹å°šä¸å¤ å®Œå–„,ä½†å°è‚©éƒ¨è¶¾éƒ¨æœ‰æ›´ç¬¦åˆç›®æ¨™çš„åˆ»ç•«'''
    )

    st.success(f"å·²é¸æ“‡èƒ¶ç‰‡: {film_type}") 
    
    # æ–‡ä»¶ä¸Šå‚³å™¨
    uploaded_image = st.file_uploader(
        "é¸æ“‡ä¸€å¼µç…§ç‰‡ä¾†é–‹å§‹æ²–æ´—",
        type=["jpg", "jpeg", "png"],
        help="ä¸Šå‚³ä¸€å¼µç…§ç‰‡æ²–æ´—è©¦è©¦çœ‹å§"
    )

# ä¸»å€åŸŸ
if uploaded_image is not None:
    try:
        # è™•ç†åœ–åƒ
        film_image, process_time, output_path = process_image(
            uploaded_image, film_type, grain_style, tone_style
        )
        
        # é¡¯ç¤ºçµæœ
        st.image(film_image, channels="BGR", use_container_width=True)
        st.success(f"åº•ç‰‡é¡¯å½±å¥½äº†ï¼Œç”¨æ™‚ {process_time:.2f}ç§’") 
        
        # æ·»åŠ ä¸‹è¼‰æŒ‰éˆ•
        # å°‡ BGR è½‰æ›ç‚º RGB ä¾› PIL ä½¿ç”¨
        film_rgb = cv2.cvtColor(film_image, cv2.COLOR_BGR2RGB)
        film_pil = Image.fromarray(film_rgb)
        
        buf = io.BytesIO()
        film_pil.save(buf, format="JPEG", quality=95)
        byte_im = buf.getvalue()
        
        st.download_button(
            label="ğŸ“¥ ä¸‹è¼‰é«˜æ¸…åœ–åƒ",
            data=byte_im,
            file_name=output_path,
            mime="image/jpeg"
        )
        
    except ValueError as e:
        st.error(f"âŒ éŒ¯èª¤: {str(e)}")
    except Exception as e:
        st.error(f"âŒ æœªé æœŸçš„éŒ¯èª¤: {str(e)}")
        st.error("è«‹å˜—è©¦é‡æ–°ä¸Šå‚³åœ–åƒæˆ–é¸æ“‡å…¶ä»–èƒ¶ç‰‡é¡å‹")
