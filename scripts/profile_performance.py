#!/usr/bin/env python3
"""
æ•ˆèƒ½åˆ†æè…³æœ¬
æ¸¬é‡å„éšæ®µè™•ç†æ™‚é–“ï¼Œè­˜åˆ¥ç“¶é ¸
"""

import numpy as np
import cv2
import time
from pathlib import Path
import sys

# æ·»åŠ å°ˆæ¡ˆæ ¹ç›®éŒ„åˆ° Python è·¯å¾‘
sys.path.insert(0, str(Path(__file__).parent.parent))

from film_models import get_film_profile, PhysicsMode


def create_test_image(size=(2000, 3000)):
    """
    å‰µå»ºæ¨™æº–æ¸¬è©¦å½±åƒ
    - é«˜å…‰ï¼šæ¨¡æ“¬è·¯ç‡ˆã€éœ“è™¹ç‡ˆ
    - ä¸­é–“èª¿ï¼šä¸€èˆ¬å ´æ™¯
    - é™°å½±ï¼šæš—éƒ¨
    """
    img = np.zeros((*size, 3), dtype=np.float32)
    
    # èƒŒæ™¯ï¼ˆä¸­é–“èª¿ 0.3ï¼‰
    img[:, :] = 0.3
    
    # æ·»åŠ é«˜å…‰å€åŸŸï¼ˆ10å€‹åœ“å½¢è·¯ç‡ˆï¼‰
    for i in range(2):
        for j in range(5):
            cx = 300 + j * 500
            cy = 300 + i * 1400
            y, x = np.ogrid[:size[0], :size[1]]
            mask = ((x - cx)**2 + (y - cy)**2) <= 30**2
            img[mask] = [0.95, 0.90, 0.85]  # æš–è‰²é«˜å…‰
    
    return img


def benchmark_function(func, *args, repeat=3, **kwargs):
    """
    æ¸¬é‡å‡½æ•¸åŸ·è¡Œæ™‚é–“ï¼ˆé‡è¤‡æ¸¬è©¦å–å¹³å‡ï¼‰
    
    Returns:
        (å¹³å‡æ™‚é–“, æ¨™æº–å·®)
    """
    times = []
    for _ in range(repeat):
        start = time.perf_counter()
        result = func(*args, **kwargs)
        elapsed = time.perf_counter() - start
        times.append(elapsed)
    
    return np.mean(times), np.std(times), result


def profile_full_pipeline(film_name="Portra400", image_size=(2000, 3000)):
    """
    å®Œæ•´æµç¨‹æ•ˆèƒ½åˆ†æ
    
    æ¸¬é‡å„éšæ®µè€—æ™‚ï¼š
    1. å…‰è­œéŸ¿æ‡‰è¨ˆç®—
    2. Bloom æ•£å°„
    3. Halation èƒŒå±¤åå°„
    4. H&D æ›²ç·š
    5. é¡†ç²’å™ªè²
    6. Tone mapping
    """
    print("=" * 70)
    print(f"  æ•ˆèƒ½åˆ†æï¼š{film_name} ({image_size[0]}Ã—{image_size[1]})")
    print("=" * 70)
    
    # è¼‰å…¥è† ç‰‡é…ç½®
    film = get_film_profile(film_name)
    
    # å‰µå»ºæ¸¬è©¦å½±åƒ
    print("\n[1] å‰µå»ºæ¸¬è©¦å½±åƒ...")
    img_rgb = create_test_image(image_size)
    print(f"    å½±åƒå°ºå¯¸: {img_rgb.shape}, è¨˜æ†¶é«”: {img_rgb.nbytes / 1024**2:.2f} MB")
    
    # åˆ†é›¢ BGR é€šé“ï¼ˆåŒ¹é…å¯¦éš›æµç¨‹ï¼‰
    b, g, r = cv2.split(img_rgb)
    
    # 2. å…‰è­œéŸ¿æ‡‰è¨ˆç®—
    print("\n[2] å…‰è­œéŸ¿æ‡‰è¨ˆç®—...")
    def spectral_response_stage():
        # ç°¡åŒ–ç‰ˆæœ¬ï¼ˆå¯¦éš›æ›´è¤‡é›œï¼‰
        response_r = 0.32*r + 0.12*g + 0.06*b
        response_g = 0.09*r + 0.45*g + 0.12*b
        response_b = 0.06*r + 0.12*g + 0.77*b
        return response_r, response_g, response_b
    
    t_spectral, std_spectral, (resp_r, resp_g, resp_b) = benchmark_function(spectral_response_stage)
    print(f"    æ™‚é–“: {t_spectral*1000:.1f} Â± {std_spectral*1000:.1f} ms")
    
    # 3. Bloom æ•£å°„ï¼ˆå¦‚æœå•Ÿç”¨ç‰©ç†æ¨¡å¼ï¼‰
    print("\n[3] Bloom æ•£å°„...")
    if film.physics_mode == PhysicsMode.PHYSICAL:
        # æ¨¡æ“¬æ³¢é•·ä¾è³´ Bloom
        def bloom_stage():
            # æå–é«˜å…‰
            threshold = 0.7
            highlight_r = np.maximum(resp_r - threshold, 0)
            highlight_g = np.maximum(resp_g - threshold, 0)
            highlight_b = np.maximum(resp_b - threshold, 0)
            
            # æ•£å°„ï¼ˆé«˜æ–¯å·ç©ï¼‰
            sigma = 20
            ksize = int(sigma * 6) | 1
            bloom_r = cv2.GaussianBlur(highlight_r * 0.08, (ksize, ksize), sigma)
            bloom_g = cv2.GaussianBlur(highlight_g * 0.08, (ksize, ksize), sigma)
            bloom_b = cv2.GaussianBlur(highlight_b * 0.08, (ksize, ksize), sigma)
            
            return bloom_r, bloom_g, bloom_b
        
        t_bloom, std_bloom, _ = benchmark_function(bloom_stage)
        print(f"    æ™‚é–“: {t_bloom*1000:.1f} Â± {std_bloom*1000:.1f} ms")
    else:
        t_bloom = 0
        print("    è·³éï¼ˆArtistic æ¨¡å¼ï¼‰")
    
    # 4. Halation èƒŒå±¤åå°„ï¼ˆæœ€å¤§ç“¶é ¸ï¼‰
    print("\n[4] Halation èƒŒå±¤åå°„...")
    if hasattr(film, 'halation_params') and film.halation_params.enabled:
        def halation_stage():
            # æå–é«˜å…‰
            threshold = 0.5
            highlight = np.maximum(resp_r - threshold, 0)
            
            # ä¸‰å±¤æŒ‡æ•¸è¿‘ä¼¼ï¼ˆå¤§æ ¸å·ç©ï¼‰
            sigma_base = 20
            ksize = 201
            
            # æ ¸ç”Ÿæˆ
            kernel_small = cv2.getGaussianKernel(ksize // 3, sigma_base)
            kernel_small = kernel_small @ kernel_small.T
            
            kernel_medium = cv2.getGaussianKernel(ksize, sigma_base * 2)
            kernel_medium = kernel_medium @ kernel_medium.T
            
            kernel_large = cv2.getGaussianKernel(ksize, sigma_base * 4)
            kernel_large = kernel_large @ kernel_large.T
            
            # ä¸‰æ¬¡å·ç©
            hal_1 = cv2.filter2D(highlight, -1, kernel_small, borderType=cv2.BORDER_REFLECT)
            hal_2 = cv2.filter2D(highlight, -1, kernel_medium, borderType=cv2.BORDER_REFLECT)
            hal_3 = cv2.filter2D(highlight, -1, kernel_large, borderType=cv2.BORDER_REFLECT)
            
            halation = 0.5 * hal_1 + 0.3 * hal_2 + 0.2 * hal_3
            
            return halation
        
        t_halation, std_halation, _ = benchmark_function(halation_stage)
        print(f"    æ™‚é–“: {t_halation*1000:.1f} Â± {std_halation*1000:.1f} ms")
        print(f"    âš ï¸  æœ€å¤§ç“¶é ¸ï¼ˆ{t_halation / (t_spectral + t_bloom + t_halation + 0.001) * 100:.1f}%ï¼‰")
    else:
        t_halation = 0
        print("    è·³éï¼ˆHalation æœªå•Ÿç”¨ï¼‰")
    
    # 5. H&D æ›²ç·š
    print("\n[5] H&D æ›²ç·š...")
    def hd_curve_stage():
        # log éŸ¿æ‡‰ + Toe/Shoulder è™•ç†
        exposure = np.clip(resp_r, 1e-10, None)
        density = 0.65 * np.log10(exposure) + 0.3
        transmittance = 10**(-density)
        return transmittance
    
    t_hd, std_hd, _ = benchmark_function(hd_curve_stage)
    print(f"    æ™‚é–“: {t_hd*1000:.1f} Â± {std_hd*1000:.1f} ms")
    
    # 6. é¡†ç²’å™ªè²
    print("\n[6] é¡†ç²’å™ªè²...")
    def grain_stage():
        grain = np.random.normal(0, 0.1, resp_r.shape).astype(np.float32)
        grain_blurred = cv2.GaussianBlur(grain, (5, 5), 1.5)
        return grain_blurred
    
    t_grain, std_grain, _ = benchmark_function(grain_stage)
    print(f"    æ™‚é–“: {t_grain*1000:.1f} Â± {std_grain*1000:.1f} ms")
    
    # 7. Tone Mapping
    print("\n[7] Tone Mapping...")
    def tone_mapping_stage():
        # S-curve + color grading
        result = resp_r ** (1/2.2)
        result = np.clip(result, 0, 1)
        return result
    
    t_tone, std_tone, _ = benchmark_function(tone_mapping_stage)
    print(f"    æ™‚é–“: {t_tone*1000:.1f} Â± {std_tone*1000:.1f} ms")
    
    # ç¸½è¨ˆ
    print("\n" + "=" * 70)
    total_time = t_spectral + t_bloom + t_halation + t_hd + t_grain + t_tone
    print(f"  ç¸½è™•ç†æ™‚é–“: {total_time*1000:.1f} ms ({total_time:.3f} s)")
    print("=" * 70)
    
    # ç“¶é ¸åˆ†æ
    print("\nğŸ” ç“¶é ¸åˆ†æ:")
    stages = [
        ("å…‰è­œéŸ¿æ‡‰", t_spectral),
        ("Bloom æ•£å°„", t_bloom),
        ("Halation åå°„", t_halation),
        ("H&D æ›²ç·š", t_hd),
        ("é¡†ç²’å™ªè²", t_grain),
        ("Tone Mapping", t_tone)
    ]
    
    for name, t in sorted(stages, key=lambda x: x[1], reverse=True):
        if total_time > 0:
            percentage = (t / total_time) * 100
            bar = "â–ˆ" * int(percentage / 2)
            print(f"  {name:20s} {t*1000:6.1f} ms  {percentage:5.1f}%  {bar}")
    
    return total_time


def compare_convolution_methods():
    """
    å°æ¯”ä¸åŒå·ç©æ–¹æ³•æ•ˆèƒ½
    """
    print("\n" + "=" * 70)
    print("  å·ç©æ–¹æ³•å°æ¯”ï¼ˆ2000Ã—3000 å½±åƒï¼‰")
    print("=" * 70)
    
    img = np.random.rand(2000, 3000).astype(np.float32)
    
    kernel_sizes = [51, 101, 201, 301]
    
    print(f"\n{'æ ¸å¤§å°':>10s}  {'filter2D':>12s}  {'GaussianBlur':>12s}  {'FFT (ç†è«–)':>12s}")
    print("-" * 70)
    
    for ksize in kernel_sizes:
        sigma = ksize / 6
        
        # filter2D
        kernel = cv2.getGaussianKernel(ksize, sigma)
        kernel = kernel @ kernel.T
        t_filter, _, _ = benchmark_function(cv2.filter2D, img, -1, kernel, 
                                           borderType=cv2.BORDER_REFLECT)
        
        # GaussianBlur
        t_gaussian, _, _ = benchmark_function(cv2.GaussianBlur, img, (ksize, ksize), sigma)
        
        # FFT ç†è«–ï¼ˆå‡è¨­ 1.7x åŠ é€Ÿï¼‰
        t_fft_theory = t_filter / 1.7 if ksize > 150 else t_filter
        
        print(f"  {ksize:3d}Ã—{ksize:3d}  {t_filter*1000:9.1f} ms  {t_gaussian*1000:9.1f} ms  {t_fft_theory*1000:9.1f} ms")


def test_fft_available():
    """æ¸¬è©¦ FFT å·ç©æ˜¯å¦å·²å¯¦ä½œ"""
    print("\n" + "=" * 70)
    print("  FFT å·ç©å¯¦ä½œæª¢æŸ¥")
    print("=" * 70)
    
    try:
        # å‹•æ…‹åŒ¯å…¥ä¸»ç¨‹å¼æ¨¡çµ„
        import importlib.util
        spec = importlib.util.spec_from_file_location("phos_main", 
                                                       Path(__file__).parent.parent / "Phos_0.3.0.py")
        phos_main = importlib.util.module_from_spec(spec)
        spec.loader.exec_module(phos_main)
        
        convolve_fft = phos_main.convolve_fft
        convolve_adaptive = phos_main.convolve_adaptive
        
        print("  âœ… convolve_fft å·²å¯¦ä½œ")
        print("  âœ… convolve_adaptive å·²å¯¦ä½œ")
        
        # ç°¡å–®æ¸¬è©¦
        img = np.random.rand(1000, 1000).astype(np.float32)
        kernel = cv2.getGaussianKernel(201, 33)
        kernel = kernel @ kernel.T
        
        t_fft, _, result_fft = benchmark_function(convolve_fft, img, kernel)
        t_spatial, _, result_spatial = benchmark_function(cv2.filter2D, img, -1, kernel,
                                                          borderType=cv2.BORDER_REFLECT)
        
        # ç²¾åº¦é©—è­‰
        diff = np.abs(result_fft - result_spatial)
        max_diff = np.max(diff)
        mean_diff = np.mean(diff)
        
        print(f"\n  æ•ˆèƒ½å°æ¯”ï¼ˆ1000Ã—1000, 201pxæ ¸ï¼‰:")
        print(f"    FFT å·ç©:   {t_fft*1000:.1f} ms")
        print(f"    ç©ºåŸŸå·ç©:   {t_spatial*1000:.1f} ms")
        print(f"    åŠ é€Ÿæ¯”:     {t_spatial / t_fft:.2f}x")
        
        print(f"\n  ç²¾åº¦é©—è­‰:")
        print(f"    æœ€å¤§èª¤å·®:   {max_diff:.6f}")
        print(f"    å¹³å‡èª¤å·®:   {mean_diff:.6f}")
        
        if max_diff < 1e-4:
            print("    âœ… ç²¾åº¦ç¬¦åˆè¦æ±‚")
        else:
            print(f"    âš ï¸  èª¤å·®éå¤§ï¼ˆé–¾å€¼ 1e-4ï¼‰")
            
    except ImportError as e:
        print(f"  âŒ ç„¡æ³•å°å…¥ FFT å‡½æ•¸: {e}")
        print("  ğŸ’¡ å»ºè­°: æª¢æŸ¥ Phos_0.3.0.py æ˜¯å¦å­˜åœ¨ convolve_fft()")


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="Phos æ•ˆèƒ½åˆ†æå·¥å…·")
    parser.add_argument("--film", default="Portra400_MediumPhysics", 
                       help="è† ç‰‡é…ç½®åç¨±")
    parser.add_argument("--size", default="2000x3000", 
                       help="æ¸¬è©¦å½±åƒå°ºå¯¸ï¼ˆæ ¼å¼ï¼šWxHï¼‰")
    parser.add_argument("--test-fft", action="store_true",
                       help="æ¸¬è©¦ FFT å·ç©å¯¦ä½œ")
    parser.add_argument("--compare-conv", action="store_true",
                       help="å°æ¯”å·ç©æ–¹æ³•")
    
    args = parser.parse_args()
    
    # è§£æå°ºå¯¸
    w, h = map(int, args.size.split('x'))
    
    # åŸ·è¡Œæ¸¬è©¦
    if args.test_fft:
        test_fft_available()
    
    if args.compare_conv:
        compare_convolution_methods()
    
    # å®Œæ•´æµç¨‹åˆ†æ
    profile_full_pipeline(args.film, (h, w))
    
    print("\n" + "=" * 70)
    print("  åˆ†æå®Œæˆ")
    print("=" * 70)
