"""
Phos 0.2.0 - Film Simulation Based on Computational Optics

"No LUTs, we calculate LUX."

ä½ è¯´çš„å¯¹ï¼Œä½†æ˜¯ Phos. æ˜¯åŸºäºã€Œè®¡ç®—å…‰å­¦ã€æ¦‚å¿µçš„èƒ¶ç‰‡æ¨¡æ‹Ÿã€‚
é€šè¿‡è®¡ç®—å…‰åœ¨åº•ç‰‡ä¸Šçš„è¡Œä¸ºï¼Œå¤ç°è‡ªç„¶ã€æŸ”ç¾ã€ç«‹ä½“çš„èƒ¶ç‰‡è´¨æ„Ÿã€‚

Version: 0.2.0 (Development - Batch Processing)
New Features: 
- æ‰¹é‡è™•ç†æ¨¡å¼ï¼ˆæ”¯æ´å¤šå¼µç…§ç‰‡åŒæ™‚è™•ç†ï¼‰
- é€²åº¦æ¢é¡¯ç¤º
- ZIP æ‰¹é‡ä¸‹è¼‰

Release Notes: See V0.2.0_ROADMAP.md for details
"""

import streamlit as st

# è®¾ç½®é¡µé¢é…ç½® 
st.set_page_config(
    page_title="Phos. èƒ¶ç‰‡æ¨¡æ‹Ÿ v0.2.0",
    page_icon="ğŸï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

import cv2
import numpy as np
import time
from PIL import Image
import io
from typing import Optional, Tuple, List
from functools import lru_cache

# ==================== ç°¡æ½”ç¾ä»£é¢¨æ ¼ CSS ====================
st.markdown("""
<style>
    /* å…¨å±€å­—é«”èˆ‡åŸºç¤æ¨£å¼ */
    @import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap');
    
    * {
        font-family: 'Inter', -apple-system, BlinkMacSystemFont, sans-serif;
    }
    
    /* ä¸»èƒŒæ™¯ - æ·±è‰²æ¼¸å±¤ */
    .stApp {
        background: linear-gradient(135deg, #0F1419 0%, #1A1F2E 100%);
        background-attachment: fixed;
    }
    
    /* ===== å´é‚Šæ¬„æ¨£å¼ ===== */
    [data-testid="stSidebar"] {
        background: rgba(26, 31, 46, 0.85) !important;
        backdrop-filter: blur(20px);
        -webkit-backdrop-filter: blur(20px);
        border-right: 1px solid rgba(255, 107, 107, 0.15);
    }
    
    [data-testid="stSidebar"] h1 {
        color: #FF6B6B !important;
        font-size: 2rem !important;
        font-weight: 700 !important;
        margin-bottom: 0.25rem !important;
    }
    
    [data-testid="stSidebar"] h2 {
        color: #B8B8B8 !important;
        font-size: 0.9rem !important;
        font-weight: 400 !important;
        margin-bottom: 2rem !important;
    }
    
    [data-testid="stSidebar"] h3 {
        color: #E8E8E8 !important;
        font-size: 1rem !important;
        font-weight: 600 !important;
        margin-top: 1.5rem !important;
        margin-bottom: 1rem !important;
    }
    
    [data-testid="stSidebar"] .stMarkdown {
        color: #B8B8B8 !important;
    }
    
    /* ===== æŒ‰éˆ•æ¨£å¼ ===== */
    .stButton > button {
        width: 100%;
        background: rgba(255, 107, 107, 0.1) !important;
        color: #FF6B6B !important;
        border: 1px solid rgba(255, 107, 107, 0.3) !important;
        border-radius: 8px !important;
        padding: 0.5rem 1rem !important;
        font-weight: 500 !important;
        transition: all 0.2s ease !important;
    }
    
    .stButton > button:hover {
        background: rgba(255, 107, 107, 0.2) !important;
        border-color: rgba(255, 107, 107, 0.5) !important;
        transform: translateY(-1px);
    }
    
    .stButton > button[kind="primary"] {
        background: linear-gradient(135deg, #FF6B6B, #FF8E8E) !important;
        color: white !important;
        border: none !important;
        box-shadow: 0 4px 12px rgba(255, 107, 107, 0.25) !important;
    }
    
    .stButton > button[kind="primary"]:hover {
        box-shadow: 0 6px 16px rgba(255, 107, 107, 0.35) !important;
    }
    
    /* ===== ä¸‹è¼‰æŒ‰éˆ• ===== */
    .stDownloadButton > button {
        width: 100%;
        background: rgba(76, 175, 80, 0.1) !important;
        color: #66BB6A !important;
        border: 1px solid rgba(76, 175, 80, 0.3) !important;
        border-radius: 8px !important;
        padding: 0.5rem 1rem !important;
        font-weight: 500 !important;
    }
    
    .stDownloadButton > button:hover {
        background: rgba(76, 175, 80, 0.2) !important;
        border-color: rgba(76, 175, 80, 0.5) !important;
    }
    
    /* ===== é¸æ“‡æ¡†æ¨£å¼ ===== */
    .stSelectbox label, .stRadio label {
        color: #E8E8E8 !important;
        font-weight: 500 !important;
        font-size: 0.9rem !important;
    }
    
    .stSelectbox > div > div {
        background: rgba(26, 31, 46, 0.6) !important;
        border: 1px solid rgba(255, 255, 255, 0.1) !important;
        border-radius: 8px !important;
        color: #E8E8E8 !important;
    }
    
    .stSelectbox > div > div:focus-within {
        border-color: rgba(255, 107, 107, 0.5) !important;
        box-shadow: 0 0 0 1px rgba(255, 107, 107, 0.2) !important;
    }
    
    /* ===== å–®é¸æŒ‰éˆ• ===== */
    .stRadio > div {
        background: transparent !important;
        gap: 0.5rem;
    }
    
    .stRadio > div > label > div {
        background: rgba(26, 31, 46, 0.6) !important;
        border: 1px solid rgba(255, 255, 255, 0.1) !important;
        border-radius: 8px !important;
        padding: 0.75rem 1rem !important;
    }
    
    .stRadio > div > label > div:hover {
        border-color: rgba(255, 107, 107, 0.3) !important;
    }
    
    /* ===== æ–‡ä»¶ä¸Šå‚³å™¨ ===== */
    [data-testid="stFileUploader"] {
        background: rgba(26, 31, 46, 0.4) !important;
        border: 2px dashed rgba(255, 107, 107, 0.3) !important;
        border-radius: 12px !important;
        padding: 1.5rem !important;
    }
    
    [data-testid="stFileUploader"]:hover {
        border-color: rgba(255, 107, 107, 0.5) !important;
        background: rgba(26, 31, 46, 0.6) !important;
    }
    
    [data-testid="stFileUploader"] label {
        color: #E8E8E8 !important;
        font-weight: 500 !important;
    }
    
    /* ===== é€²åº¦æ¢ ===== */
    .stProgress > div > div > div {
        background: linear-gradient(90deg, #FF6B6B, #FFB4B4) !important;
    }
    
    .stProgress > div > div {
        background: rgba(26, 31, 46, 0.6) !important;
        border-radius: 8px !important;
    }
    
    /* ===== è­¦å‘Šæ¡† ===== */
    .stAlert {
        background: rgba(26, 31, 46, 0.8) !important;
        border-radius: 8px !important;
        border-left: 3px solid !important;
        padding: 0.75rem 1rem !important;
    }
    
    div[data-baseweb="notification"] {
        background: rgba(26, 31, 46, 0.8) !important;
        border-radius: 8px !important;
    }
    
    /* ===== åœ–ç‰‡å®¹å™¨ ===== */
    [data-testid="stImage"] {
        border-radius: 12px !important;
        overflow: hidden !important;
        box-shadow: 0 8px 32px rgba(0, 0, 0, 0.3) !important;
    }
    
    /* ===== åˆ†éš”ç·š ===== */
    hr {
        border: none !important;
        height: 1px !important;
        background: rgba(255, 107, 107, 0.2) !important;
        margin: 1.5rem 0 !important;
    }
    
    /* ===== æ¨™é¡Œæ¨£å¼ ===== */
    h1 {
        color: #FF6B6B !important;
        font-weight: 700 !important;
    }
    
    h2, h3 {
        color: #E8E8E8 !important;
        font-weight: 600 !important;
    }
    
    p, li {
        color: #B8B8B8 !important;
        line-height: 1.6 !important;
    }
    
    /* ===== æ»¾å‹•æ¢ ===== */
    ::-webkit-scrollbar {
        width: 8px;
        height: 8px;
    }
    
    ::-webkit-scrollbar-track {
        background: rgba(26, 31, 46, 0.3);
    }
    
    ::-webkit-scrollbar-thumb {
        background: rgba(255, 107, 107, 0.3);
        border-radius: 4px;
    }
    
    ::-webkit-scrollbar-thumb:hover {
        background: rgba(255, 107, 107, 0.5);
    }
    
    /* ===== éš±è—å…ƒç´  ===== */
    #MainMenu {visibility: hidden;}
    footer {visibility: hidden;}
    
    /* ===== å®¹å™¨é–“è· ===== */
    .block-container {
        padding-top: 2rem;
        padding-bottom: 2rem;
        max-width: 1200px;
    }
    
    [data-testid="column"] {
        padding: 0.5rem;
    }
</style>
""", unsafe_allow_html=True)

# å°å…¥æ‰¹é‡è™•ç†æ¨¡å¡Š
from phos_batch import (
    BatchProcessor,
    BatchResult,
    create_zip_archive,
    generate_zip_filename,
    validate_batch_size,
    estimate_processing_time
)

# å°å…¥èƒ¶ç‰‡æ¨¡å‹
from film_models import (
    get_film_profile, 
    FilmProfile, 
    EmulsionLayer,
    STANDARD_IMAGE_SIZE,
    SENSITIVITY_MIN,
    SENSITIVITY_MAX,
    SENSITIVITY_SCALE,
    SENSITIVITY_BASE,
    BLOOM_STRENGTH_FACTOR,
    BLOOM_RADIUS_FACTOR,
    BLOOM_RADIUS_MIN,
    BLOOM_RADIUS_MAX,
    BASE_DIFFUSION_FACTOR,
    GRAIN_WEIGHT_MIN,
    GRAIN_WEIGHT_MAX,
    GRAIN_SENS_MIN,
    GRAIN_SENS_MAX,
    GRAIN_BLUR_KERNEL,
    GRAIN_BLUR_SIGMA,
    REINHARD_GAMMA_ADJUSTMENT,
    FILMIC_EXPOSURE_SCALE
)


# ==================== å¿«å–è£é£¾å™¨ ====================

@st.cache_resource
def get_cached_film_profile(film_type: str) -> FilmProfile:
    """
    å¿«å–èƒ¶ç‰‡é…ç½®ï¼Œé¿å…é‡è¤‡å‰µå»º
    
    Args:
        film_type: èƒ¶ç‰‡é¡å‹
        
    Returns:
        FilmProfile: å¿«å–çš„èƒ¶ç‰‡é…ç½®
    """
    return get_film_profile(film_type)


# ==================== åœ–åƒé è™•ç† ====================

def standardize(image: np.ndarray) -> np.ndarray:
    """
    æ¨™æº–åŒ–åœ–åƒå°ºå¯¸
    
    å°‡åœ–åƒçš„çŸ­é‚Šèª¿æ•´ç‚ºæ¨™æº–å°ºå¯¸ï¼ˆ3000pxï¼‰ï¼Œä¿æŒå¯¬é«˜æ¯”
    
    Args:
        image: è¼¸å…¥åœ–åƒ (BGR æ ¼å¼)
        
    Returns:
        èª¿æ•´å¾Œçš„åœ–åƒ
    """
    height, width = image.shape[:2]
    
    # ç¢ºå®šç¸®æ”¾æ¯”ä¾‹
    if height < width:
        # ç«–åœ– - é«˜åº¦ç‚ºçŸ­é‚Š
        scale_factor = STANDARD_IMAGE_SIZE / height
        new_height = STANDARD_IMAGE_SIZE
        new_width = int(width * scale_factor)
    else:
        # æ©«åœ– - å¯¬åº¦ç‚ºçŸ­é‚Š
        scale_factor = STANDARD_IMAGE_SIZE / width
        new_width = STANDARD_IMAGE_SIZE
        new_height = int(height * scale_factor)
    
    # ç¢ºä¿æ–°å°ºå¯¸ç‚ºå¶æ•¸ï¼ˆé¿å…æŸäº›è™•ç†å•é¡Œï¼‰
    new_width = new_width + 1 if new_width % 2 != 0 else new_width
    new_height = new_height + 1 if new_height % 2 != 0 else new_height
    
    # é¸æ“‡é©ç•¶çš„æ’å€¼æ–¹æ³•
    interpolation = cv2.INTER_AREA if scale_factor < 1 else cv2.INTER_LANCZOS4
    resized_image = cv2.resize(image, (new_width, new_height), interpolation=interpolation)
    
    return resized_image


# ==================== å…‰åº¦è¨ˆç®— ====================

def luminance(image: np.ndarray, film: FilmProfile) -> Tuple[Optional[np.ndarray], Optional[np.ndarray], Optional[np.ndarray], np.ndarray]:
    """
    è¨ˆç®—äº®åº¦åœ–åƒï¼Œæ¨¡æ“¬èƒ¶ç‰‡æ„Ÿå…‰å±¤çš„å…‰è­œéŸ¿æ‡‰
    
    é€™å€‹å‡½æ•¸æ¨¡æ“¬äº†å…‰åœ¨èƒ¶ç‰‡ä¸åŒæ„Ÿå…‰å±¤ä¸­çš„å¸æ”¶éç¨‹ã€‚
    æ¯å€‹æ„Ÿå…‰å±¤å°ä¸åŒæ³¢é•·çš„å…‰æœ‰ä¸åŒçš„æ•æ„Ÿåº¦ã€‚
    
    Args:
        image: è¼¸å…¥åœ–åƒ (BGR æ ¼å¼ï¼Œ0-255)
        film: èƒ¶ç‰‡é…ç½®å°è±¡
        
    Returns:
        (lux_r, lux_g, lux_b, lux_total): å„é€šé“çš„å…‰åº¦éŸ¿æ‡‰ (0-1 ç¯„åœ)
            - å½©è‰²èƒ¶ç‰‡: lux_r/g/b ç‚ºå„å±¤éŸ¿æ‡‰ï¼Œlux_total ç‚ºå…¨è‰²å±¤
            - é»‘ç™½èƒ¶ç‰‡: åƒ… lux_total æœ‰å€¼ï¼Œå…¶é¤˜ç‚º None
    """
    # åˆ†é›¢ RGB é€šé“
    b, g, r = cv2.split(image)
    
    # è½‰æ›ç‚ºæµ®é»æ•¸ (0-1 ç¯„åœ)
    r_float = r.astype(np.float32) / 255.0
    g_float = g.astype(np.float32) / 255.0
    b_float = b.astype(np.float32) / 255.0
    
    # ç²å–å…‰è­œéŸ¿æ‡‰ä¿‚æ•¸
    r_r, r_g, r_b, g_r, g_g, g_b, b_r, b_g, b_b, t_r, t_g, t_b = film.get_spectral_response()
    
    # æ¨¡æ“¬ä¸åŒä¹³åŠ‘å±¤çš„å¸æ”¶ç‰¹æ€§ï¼ˆå…‰è­œæ•æ„Ÿåº¦çš„ç·šæ€§çµ„åˆï¼‰
    if film.color_type == "color":
        lux_r = r_r * r_float + r_g * g_float + r_b * b_float
        lux_g = g_r * r_float + g_g * g_float + g_b * b_float
        lux_b = b_r * r_float + b_g * g_float + b_b * b_float
        lux_total = t_r * r_float + t_g * g_float + t_b * b_float
    else:
        lux_total = t_r * r_float + t_g * g_float + t_b * b_float
        lux_r = None
        lux_g = None
        lux_b = None

    return lux_r, lux_g, lux_b, lux_total


def average_luminance(lux_total: np.ndarray) -> float:
    """
    è¨ˆç®—åœ–åƒçš„å¹³å‡äº®åº¦
    
    Args:
        lux_total: å…¨è‰²é€šé“çš„å…‰åº¦æ•¸æ“š
        
    Returns:
        å¹³å‡äº®åº¦å€¼ (0-1 ç¯„åœ)
    """
    avg_lux = np.mean(lux_total)
    return np.clip(avg_lux, 0, 1)


# ==================== èƒ¶ç‰‡é¡†ç²’æ•ˆæœ ====================

def generate_grain_for_channel(lux_channel: np.ndarray, sens: float) -> np.ndarray:
    """
    ç‚ºå–®å€‹é€šé“ç”Ÿæˆèƒ¶ç‰‡é¡†ç²’å™ªè²
    
    èƒ¶ç‰‡é¡†ç²’æ˜¯ç”±æ–¼éŠ€é¹½æ™¶é«”çš„éš¨æ©Ÿåˆ†å¸ƒç”¢ç”Ÿçš„ã€‚
    é€™å€‹å‡½æ•¸ä½¿ç”¨åŠ æ¬Šéš¨æ©Ÿå™ªè²ä¾†æ¨¡æ“¬é€™ç¨®æ•ˆæœã€‚
    
    Args:
        lux_channel: å…‰åº¦é€šé“æ•¸æ“š (0-1 ç¯„åœ)
        sens: æ•æ„Ÿåº¦åƒæ•¸
        
    Returns:
        åŠ æ¬Šå™ªè² (-1 åˆ° 1 ç¯„åœ)
    """
    # å‰µå»ºæ­£è² å™ªè²ï¼ˆä½¿ç”¨å¹³æ–¹æ­£æ…‹åˆ†ä½ˆç”¢ç”Ÿæ›´è‡ªç„¶çš„é¡†ç²’ï¼‰
    noise = np.random.normal(0, 1, lux_channel.shape).astype(np.float32)
    noise = noise ** 2
    noise = noise * np.random.choice([-1, 1], lux_channel.shape)
    
    # å‰µå»ºæ¬Šé‡åœ–ï¼ˆä¸­ç­‰äº®åº¦å€åŸŸæ¬Šé‡æœ€é«˜ï¼Œæ¨¡æ“¬èƒ¶ç‰‡é¡†ç²’åœ¨ä¸­é–“èª¿æœ€æ˜é¡¯çš„ç‰¹æ€§ï¼‰
    weights = (0.5 - np.abs(lux_channel - 0.5)) * 2
    weights = np.clip(weights, GRAIN_WEIGHT_MIN, GRAIN_WEIGHT_MAX)
    
    # æ‡‰ç”¨æ¬Šé‡å’Œæ•æ„Ÿåº¦
    sens_grain = np.clip(sens, GRAIN_SENS_MIN, GRAIN_SENS_MAX)
    weighted_noise = noise * weights * sens_grain
    
    # æ·»åŠ è¼•å¾®æ¨¡ç³Šä½¿é¡†ç²’æ›´æŸ”å’Œ
    weighted_noise = cv2.GaussianBlur(weighted_noise, GRAIN_BLUR_KERNEL, GRAIN_BLUR_SIGMA)
    
    return np.clip(weighted_noise, -1, 1)


def apply_grain(lux_r: Optional[np.ndarray], lux_g: Optional[np.ndarray], 
                lux_b: Optional[np.ndarray], lux_total: np.ndarray, 
                film: FilmProfile, sens: float) -> Tuple[Optional[np.ndarray], Optional[np.ndarray], Optional[np.ndarray], Optional[np.ndarray]]:
    """
    ç”Ÿæˆèƒ¶ç‰‡é¡†ç²’æ•ˆæœ
    
    Args:
        lux_r, lux_g, lux_b: RGB é€šé“çš„å…‰åº¦æ•¸æ“šï¼ˆå½©è‰²èƒ¶ç‰‡ï¼‰
        lux_total: å…¨è‰²é€šé“çš„å…‰åº¦æ•¸æ“š
        film: èƒ¶ç‰‡é…ç½®å°è±¡
        sens: æ•æ„Ÿåº¦åƒæ•¸
        
    Returns:
        (weighted_noise_r, weighted_noise_g, weighted_noise_b, weighted_noise_total): å„é€šé“çš„é¡†ç²’å™ªè²
    """
    if film.color_type == "color" and all([lux_r is not None, lux_g is not None, lux_b is not None]):
        # å½©è‰²èƒ¶ç‰‡ï¼šç‚ºæ¯å€‹é€šé“ç”Ÿæˆç¨ç«‹çš„é¡†ç²’
        weighted_noise_r = generate_grain_for_channel(lux_r, sens)
        weighted_noise_g = generate_grain_for_channel(lux_g, sens)
        weighted_noise_b = generate_grain_for_channel(lux_b, sens)
        weighted_noise_total = None
    else:
        # é»‘ç™½èƒ¶ç‰‡ï¼šåƒ…ç”Ÿæˆå…¨è‰²é€šé“çš„é¡†ç²’
        weighted_noise_total = generate_grain_for_channel(lux_total, sens)
        weighted_noise_r = None
        weighted_noise_g = None
        weighted_noise_b = None
    
    return weighted_noise_r, weighted_noise_g, weighted_noise_b, weighted_noise_total


# ==================== Tone Mapping ====================

def apply_reinhard_to_channel(lux: np.ndarray, gamma: float, color_mode: bool = False) -> np.ndarray:
    """
    å°å–®å€‹é€šé“æ‡‰ç”¨ Reinhard tone mapping
    
    Reinhard tone mapping æ˜¯ä¸€ç¨®å…¨å±€ tone mapping ç®—æ³•ï¼Œ
    ä½¿ç”¨ç°¡å–®çš„å…¬å¼å°‡ HDR æ˜ å°„åˆ° LDRã€‚
    
    Args:
        lux: è¼¸å…¥å…‰åº¦æ•¸æ“š
        gamma: Gamma å€¼
        color_mode: æ˜¯å¦ç‚ºå½©è‰²æ¨¡å¼ï¼ˆå½±éŸ¿ gamma èª¿æ•´ï¼‰
        
    Returns:
        æ˜ å°„å¾Œçš„çµæœ (0-1 ç¯„åœ)
    """
    # Reinhard tone mapping: L' = L * L / (1 + L)
    mapped = lux * (lux / (1.0 + lux))
    
    # æ‡‰ç”¨ gamma æ ¡æ­£
    gamma_adj = REINHARD_GAMMA_ADJUSTMENT if color_mode else 1.0
    mapped = np.power(np.maximum(mapped, 0), gamma_adj / gamma)
    
    return np.clip(mapped, 0, 1)


def apply_reinhard(lux_r: Optional[np.ndarray], lux_g: Optional[np.ndarray], 
                   lux_b: Optional[np.ndarray], lux_total: np.ndarray, 
                   film: FilmProfile) -> Tuple[Optional[np.ndarray], Optional[np.ndarray], Optional[np.ndarray], Optional[np.ndarray]]:
    """
    Reinhard tone mapping ç®—æ³•
    
    Args:
        lux_r, lux_g, lux_b: RGB é€šé“çš„å…‰åº¦æ•¸æ“š
        lux_total: å…¨è‰²é€šé“çš„å…‰åº¦æ•¸æ“š
        film: èƒ¶ç‰‡é…ç½®å°è±¡
        
    Returns:
        (result_r, result_g, result_b, result_total): æ˜ å°„å¾Œçš„å„é€šé“æ•¸æ“š
    """
    gamma = film.tone_params.gamma
    
    if film.color_type == "color" and all([lux_r is not None, lux_g is not None, lux_b is not None]):
        result_r = apply_reinhard_to_channel(lux_r, gamma, color_mode=True)
        result_g = apply_reinhard_to_channel(lux_g, gamma, color_mode=True)
        result_b = apply_reinhard_to_channel(lux_b, gamma, color_mode=True)
        result_total = None
    else:
        result_total = apply_reinhard_to_channel(lux_total, gamma, color_mode=False)
        result_r = None
        result_g = None
        result_b = None

    return result_r, result_g, result_b, result_total


def apply_filmic_to_channel(lux: np.ndarray, film: FilmProfile) -> np.ndarray:
    """
    å°å–®å€‹é€šé“æ‡‰ç”¨ Filmic tone mapping
    
    Filmic tone mapping ä½¿ç”¨åˆ†æ®µæ›²ç·šæ¨¡æ“¬çœŸå¯¦èƒ¶ç‰‡çš„ç‰¹æ€§æ›²ç·šã€‚
    ç›¸æ¯” Reinhardï¼Œå®ƒå°é«˜å…‰å’Œé™°å½±æœ‰æ›´å¥½çš„æ§åˆ¶ã€‚
    
    Args:
        lux: è¼¸å…¥å…‰åº¦æ•¸æ“š
        film: èƒ¶ç‰‡é…ç½®å°è±¡
        
    Returns:
        æ˜ å°„å¾Œçš„çµæœ
        
    Note:
        ç‰¹æ€§æ›²ç·šä¸‰å€‹é—œéµéƒ¨åˆ†ï¼š
        - Shoulder (è‚©éƒ¨): æ§åˆ¶é«˜å…‰éæ¸¡ï¼Œé¿å…é«˜å…‰æº¢å‡º
        - Linear (ç·šæ€§æ®µ): æ§åˆ¶ä¸­é–“èª¿éŸ¿æ‡‰
        - Toe (è¶¾éƒ¨): æ§åˆ¶é™°å½±éæ¸¡ï¼Œä¿ç•™é™°å½±ç´°ç¯€
    """
    # ç¢ºä¿éè² å€¼
    lux = np.maximum(lux, 0)
    
    # æ‡‰ç”¨æ›å…‰å’Œ gamma
    params = film.tone_params
    x = FILMIC_EXPOSURE_SCALE * np.power(lux, params.gamma)
    
    # Filmic curve: åˆ†æ®µæ›²ç·šå…¬å¼
    A, B, C, D, E, F = (
        params.shoulder_strength, 
        params.linear_strength,
        params.linear_angle, 
        params.toe_strength,
        params.toe_numerator, 
        params.toe_denominator
    )
    
    numerator = x * (A * x + C * B) + D * E
    denominator = x * (A * x + B) + D * F
    
    # é¿å…é™¤é›¶
    with np.errstate(divide='ignore', invalid='ignore'):
        result = np.where(
            denominator != 0,
            (numerator / denominator) - E / F,
            0
        )
    
    return result


def apply_filmic(lux_r: Optional[np.ndarray], lux_g: Optional[np.ndarray], 
                 lux_b: Optional[np.ndarray], lux_total: np.ndarray, 
                 film: FilmProfile) -> Tuple[Optional[np.ndarray], Optional[np.ndarray], Optional[np.ndarray], Optional[np.ndarray]]:
    """
    Filmic tone mapping ç®—æ³•
    
    Args:
        lux_r, lux_g, lux_b: RGB é€šé“çš„å…‰åº¦æ•¸æ“š
        lux_total: å…¨è‰²é€šé“çš„å…‰åº¦æ•¸æ“š
        film: èƒ¶ç‰‡é…ç½®å°è±¡
        
    Returns:
        (result_r, result_g, result_b, result_total): æ˜ å°„å¾Œçš„å„é€šé“æ•¸æ“š
    """
    if film.color_type == "color" and all([lux_r is not None, lux_g is not None, lux_b is not None]):
        result_r = apply_filmic_to_channel(lux_r, film)
        result_g = apply_filmic_to_channel(lux_g, film)
        result_b = apply_filmic_to_channel(lux_b, film)
        result_total = None
    else:
        result_total = apply_filmic_to_channel(lux_total, film)
        result_r = None
        result_g = None
        result_b = None
    
    return result_r, result_g, result_b, result_total


# ==================== å…‰å­¸æ“´æ•£æ•ˆæœ ====================

def calculate_bloom_params(avg_lux: float, sens_factor: float) -> Tuple[float, int, float, float]:
    """
    æ ¹æ“šå¹³å‡äº®åº¦è¨ˆç®—å…‰æšˆåƒæ•¸
    
    Args:
        avg_lux: å¹³å‡äº®åº¦
        sens_factor: èƒ¶ç‰‡æ•æ„Ÿä¿‚æ•¸
        
    Returns:
        (sens, rads, strg, base): æ•æ„Ÿåº¦ã€æ“´æ•£åŠå¾‘ã€å…‰æšˆå¼·åº¦ã€åŸºç¤æ“´æ•£
    """
    # æ ¹æ“šå¹³å‡äº®åº¦è¨ˆç®—æ•æ„Ÿåº¦ï¼ˆæš—åœ–æ›´æ•æ„Ÿï¼‰
    sens = float((1.0 - avg_lux) * SENSITIVITY_SCALE + SENSITIVITY_BASE)
    sens = float(np.clip(sens, SENSITIVITY_MIN, SENSITIVITY_MAX))
    
    # è¨ˆç®—å…‰æšˆå¼·åº¦å’Œæ“´æ•£åŠå¾‘
    strg = float(BLOOM_STRENGTH_FACTOR * (sens ** 2) * sens_factor)
    rads = int(BLOOM_RADIUS_FACTOR * (sens ** 2) * sens_factor)
    rads = int(np.clip(rads, BLOOM_RADIUS_MIN, BLOOM_RADIUS_MAX))
    
    # åŸºç¤æ“´æ•£å¼·åº¦
    base = float(BASE_DIFFUSION_FACTOR * sens_factor)
    
    return sens, rads, strg, base


def apply_bloom_to_channel(lux: np.ndarray, sens: float, rads: int, strg: float, base: float, 
                           blur_scale: int, blur_sigma_scale: float) -> np.ndarray:
    """
    å°å–®å€‹é€šé“æ‡‰ç”¨å…‰æšˆæ•ˆæœ
    
    å…‰æšˆï¼ˆHalationï¼‰æ˜¯ç”±æ–¼å…‰åœ¨èƒ¶ç‰‡ä¸­çš„æ•£å°„å’Œåå°„ç”¢ç”Ÿçš„ã€‚
    é«˜å…‰å€åŸŸæœƒç”¢ç”ŸæŸ”å’Œçš„å…‰æšˆï¼Œé€™æ˜¯èƒ¶ç‰‡çš„ç‰¹å¾µä¹‹ä¸€ã€‚
    
    Args:
        lux: å…‰åº¦é€šé“æ•¸æ“š
        sens: æ•æ„Ÿåº¦
        rads: æ“´æ•£åŠå¾‘
        strg: å…‰æšˆå¼·åº¦
        base: åŸºç¤æ“´æ•£å¼·åº¦
        blur_scale: æ¨¡ç³Šæ ¸å¤§å°å€æ•¸
        blur_sigma_scale: æ¨¡ç³Š sigma å€æ•¸
        
    Returns:
        å…‰æšˆæ•ˆæœ
    """
    # å‰µå»ºæ¬Šé‡ï¼ˆé«˜å…‰å€åŸŸæ¬Šé‡æ›´é«˜ï¼‰
    weights = (base + lux ** 2) * sens
    weights = np.clip(weights, 0, 1)
    
    # è¨ˆç®—æ¨¡ç³Šæ ¸å¤§å°ï¼ˆå¿…é ˆç‚ºå¥‡æ•¸ï¼‰
    ksize = rads * blur_scale
    ksize = ksize if ksize % 2 == 1 else ksize + 1
    
    # å‰µå»ºå…‰æšˆå±¤ï¼ˆä½¿ç”¨é«˜æ–¯æ¨¡ç³Šæ¨¡æ“¬å…‰çš„æ“´æ•£ï¼‰
    bloom_layer = cv2.GaussianBlur(lux * weights, (ksize, ksize), sens * blur_sigma_scale)
    
    # æ‡‰ç”¨å…‰æšˆ
    bloom_effect = bloom_layer * weights * strg
    bloom_effect = bloom_effect / (1.0 + bloom_effect)  # é¿å…éæ›
    
    return bloom_effect


def combine_layers_for_channel(bloom: np.ndarray, lux: np.ndarray, layer: EmulsionLayer,
                               grain_r: Optional[np.ndarray], grain_g: Optional[np.ndarray], 
                               grain_b: Optional[np.ndarray], grain_total: float,
                               use_grain: bool) -> np.ndarray:
    """
    çµ„åˆæ•£å°„å…‰ã€ç›´å°„å…‰å’Œé¡†ç²’æ•ˆæœ
    
    Args:
        bloom: å…‰æšˆæ•ˆæœ
        lux: åŸå§‹å…‰åº¦æ•¸æ“š
        layer: æ„Ÿå…‰å±¤åƒæ•¸
        grain_r, grain_g, grain_b: RGB é¡†ç²’å™ªè²
        grain_total: å…¨è‰²é¡†ç²’å¼·åº¦
        use_grain: æ˜¯å¦ä½¿ç”¨é¡†ç²’
        
    Returns:
        çµ„åˆå¾Œçš„å…‰åº¦æ•¸æ“š
    """
    # æ•£å°„å…‰ + ç›´å°„å…‰ï¼ˆéç·šæ€§éŸ¿æ‡‰ï¼‰
    result = bloom * layer.diffuse_light + np.power(lux, layer.response_curve) * layer.direct_light
    
    # æ·»åŠ é¡†ç²’
    if use_grain:
        # å½©è‰²èƒ¶ç‰‡çš„é¡†ç²’æœ‰è‰²å½©ç›¸é—œæ€§
        if grain_r is not None and grain_g is not None and grain_b is not None:
            result += (grain_r * layer.grain_intensity + 
                      grain_g * grain_total + 
                      grain_b * grain_total)
        elif grain_r is not None:
            result += grain_r * layer.grain_intensity
    
    return result


def optical_processing(lux_r: Optional[np.ndarray], lux_g: Optional[np.ndarray], 
                      lux_b: Optional[np.ndarray], lux_total: np.ndarray,
                      film: FilmProfile, grain_style: str, tone_style: str) -> np.ndarray:
    """
    å…‰å­¸è™•ç†ä¸»å‡½æ•¸
    
    é€™æ˜¯æ•´å€‹èƒ¶ç‰‡æ¨¡æ“¬çš„æ ¸å¿ƒï¼ŒåŒ…å«ï¼š
    1. è¨ˆç®—è‡ªé©æ‡‰åƒæ•¸
    2. æ‡‰ç”¨å…‰æšˆæ•ˆæœï¼ˆHalation/Bloomï¼‰
    3. æ‡‰ç”¨é¡†ç²’æ•ˆæœ
    4. çµ„åˆæ•£å°„å…‰å’Œç›´å°„å…‰
    5. Tone mapping
    6. åˆæˆæœ€çµ‚åœ–åƒ
    
    Args:
        lux_r, lux_g, lux_b: RGB é€šé“çš„å…‰åº¦æ•¸æ“š
        lux_total: å…¨è‰²é€šé“çš„å…‰åº¦æ•¸æ“š
        film: èƒ¶ç‰‡é…ç½®å°è±¡
        grain_style: é¡†ç²’é¢¨æ ¼
        tone_style: Tone mapping é¢¨æ ¼
        
    Returns:
        è™•ç†å¾Œçš„åœ–åƒ (0-255 uint8)
    """
    # 1. è¨ˆç®—è‡ªé©æ‡‰åƒæ•¸
    avg_lux = average_luminance(lux_total)
    sens, rads, strg, base = calculate_bloom_params(avg_lux, film.sensitivity_factor)
    
    # 2. æ‡‰ç”¨é¡†ç²’ï¼ˆå¦‚æœéœ€è¦ï¼‰
    use_grain = (grain_style != "ä¸ä½¿ç”¨")
    if use_grain:
        grain_r, grain_g, grain_b, grain_total_noise = apply_grain(
            lux_r, lux_g, lux_b, lux_total, film, sens
        )
    else:
        grain_r = grain_g = grain_b = grain_total_noise = None
    
    # 3. è™•ç†å„é€šé“
    if film.color_type == "color" and all([lux_r is not None, lux_g is not None, lux_b is not None]):
        # å½©è‰²èƒ¶ç‰‡ï¼šè™•ç† RGB ä¸‰å€‹é€šé“
        # ä¸åŒé¡è‰²é€šé“çš„å…‰æšˆç‰¹æ€§ä¸åŒï¼ˆç´…è‰²æ“´æ•£æœ€å»£ï¼Œè—è‰²æœ€çª„ï¼‰
        bloom_r = apply_bloom_to_channel(lux_r, sens, rads, strg, base, blur_scale=3, blur_sigma_scale=55)
        bloom_g = apply_bloom_to_channel(lux_g, sens, rads, strg, base, blur_scale=2, blur_sigma_scale=35)
        bloom_b = apply_bloom_to_channel(lux_b, sens, rads, strg, base, blur_scale=1, blur_sigma_scale=15)
        
        # çµ„åˆå„å±¤
        lux_r_final = combine_layers_for_channel(
            bloom_r, lux_r, film.red_layer, grain_r, grain_g, grain_b, 
            film.panchromatic_layer.grain_intensity, use_grain
        )
        lux_g_final = combine_layers_for_channel(
            bloom_g, lux_g, film.green_layer, grain_r, grain_g, grain_b,
            film.panchromatic_layer.grain_intensity, use_grain
        )
        lux_b_final = combine_layers_for_channel(
            bloom_b, lux_b, film.blue_layer, grain_r, grain_g, grain_b,
            film.panchromatic_layer.grain_intensity, use_grain
        )
        
        # 4. Tone mapping
        if tone_style == "filmic":
            result_r, result_g, result_b, _ = apply_filmic(lux_r_final, lux_g_final, lux_b_final, lux_total, film)
        else:
            result_r, result_g, result_b, _ = apply_reinhard(lux_r_final, lux_g_final, lux_b_final, lux_total, film)
        
        # 5. åˆæˆæœ€çµ‚åœ–åƒ
        combined_r = (result_r * 255).astype(np.uint8)
        combined_g = (result_g * 255).astype(np.uint8)
        combined_b = (result_b * 255).astype(np.uint8)
        final_image = cv2.merge([combined_b, combined_g, combined_r])
        
    else:
        # é»‘ç™½èƒ¶ç‰‡ï¼šåƒ…è™•ç†å…¨è‰²é€šé“
        bloom = apply_bloom_to_channel(lux_total, sens, rads, strg, base, blur_scale=3, blur_sigma_scale=55)
        
        # çµ„åˆå±¤
        if use_grain and grain_total_noise is not None:
            lux_final = (bloom * film.panchromatic_layer.diffuse_light + 
                        np.power(lux_total, film.panchromatic_layer.response_curve) * film.panchromatic_layer.direct_light +
                        grain_total_noise * film.panchromatic_layer.grain_intensity)
        else:
            lux_final = (bloom * film.panchromatic_layer.diffuse_light + 
                        np.power(lux_total, film.panchromatic_layer.response_curve) * film.panchromatic_layer.direct_light)
        
        # Tone mapping
        if tone_style == "filmic":
            _, _, _, result_total = apply_filmic(None, None, None, lux_final, film)
        else:
            _, _, _, result_total = apply_reinhard(None, None, None, lux_final, film)
        
        # åˆæˆæœ€çµ‚åœ–åƒ
        final_image = (result_total * 255).astype(np.uint8)
    
    return final_image


# ==================== ä¸»è™•ç†æµç¨‹ ====================

def adjust_grain_intensity(film: FilmProfile, grain_style: str) -> FilmProfile:
    """
    æ ¹æ“šç”¨æˆ¶é¸æ“‡èª¿æ•´é¡†ç²’å¼·åº¦
    
    Args:
        film: åŸå§‹èƒ¶ç‰‡é…ç½®
        grain_style: é¡†ç²’é¢¨æ ¼é¸æ“‡
        
    Returns:
        èª¿æ•´å¾Œçš„èƒ¶ç‰‡é…ç½®
    """
    # é¡†ç²’å¼·åº¦å€æ•¸
    multipliers = {
        "é»˜èª": 1.0,
        "æŸ”å’Œ": 0.5,
        "è¼ƒç²—": 1.5,
        "ä¸ä½¿ç”¨": 0.0
    }
    
    multiplier = multipliers.get(grain_style, 1.0)
    
    # å‰µå»ºæ–°çš„æ„Ÿå…‰å±¤ï¼ˆä¸ä¿®æ”¹åŸå§‹é…ç½®ï¼‰
    if film.color_type == "color" and film.red_layer and film.green_layer and film.blue_layer:
        from dataclasses import replace
        return replace(
            film,
            red_layer=replace(film.red_layer, grain_intensity=film.red_layer.grain_intensity * multiplier),
            green_layer=replace(film.green_layer, grain_intensity=film.green_layer.grain_intensity * multiplier),
            blue_layer=replace(film.blue_layer, grain_intensity=film.blue_layer.grain_intensity * multiplier),
            panchromatic_layer=replace(film.panchromatic_layer, grain_intensity=film.panchromatic_layer.grain_intensity * multiplier)
        )
    else:
        from dataclasses import replace
        return replace(
            film,
            panchromatic_layer=replace(film.panchromatic_layer, grain_intensity=film.panchromatic_layer.grain_intensity * multiplier)
        )


def process_image(uploaded_image, film_type: str, grain_style: str, tone_style: str) -> Tuple[np.ndarray, float, str]:
    """
    è™•ç†ä¸Šå‚³çš„åœ–åƒ
    
    é€™æ˜¯ä¸»è¦çš„è™•ç†æµç¨‹ï¼Œå”èª¿æ‰€æœ‰æ­¥é©Ÿï¼š
    1. è®€å–åœ–åƒ
    2. ç²å–èƒ¶ç‰‡é…ç½®
    3. æ¨™æº–åŒ–å°ºå¯¸
    4. è¨ˆç®—å…‰åº¦éŸ¿æ‡‰
    5. æ‡‰ç”¨å…‰å­¸æ•ˆæœ
    
    Args:
        uploaded_image: ä¸Šå‚³çš„åœ–åƒæ–‡ä»¶
        film_type: èƒ¶ç‰‡é¡å‹
        grain_style: é¡†ç²’é¢¨æ ¼
        tone_style: Tone mapping é¢¨æ ¼
        
    Returns:
        (è™•ç†å¾Œçš„åœ–åƒ, è™•ç†æ™‚é–“, è¼¸å‡ºæ–‡ä»¶å)
        
    Raises:
        ValueError: åœ–åƒè®€å–å¤±æ•—æˆ–èƒ¶ç‰‡é¡å‹ç„¡æ•ˆ
    """
    start_time = time.time()
    
    try:
        # 1. è®€å–ä¸Šå‚³çš„æ–‡ä»¶
        file_bytes = np.asarray(bytearray(uploaded_image.read()), dtype=np.uint8)
        image = cv2.imdecode(file_bytes, cv2.IMREAD_COLOR)
        
        if image is None:
            raise ValueError("ç„¡æ³•è®€å–åœ–åƒæ–‡ä»¶ï¼Œè«‹ç¢ºä¿ä¸Šå‚³çš„æ˜¯æœ‰æ•ˆçš„åœ–åƒæ ¼å¼")
        
        # 2. ç²å–èƒ¶ç‰‡é…ç½®ï¼ˆä½¿ç”¨å¿«å–ï¼‰
        film = get_cached_film_profile(film_type)
        
        # 3. èª¿æ•´é¡†ç²’å¼·åº¦
        film = adjust_grain_intensity(film, grain_style)
        
        # 4. æ¨™æº–åŒ–åœ–åƒå°ºå¯¸
        image = standardize(image)
        
        # 5. è¨ˆç®—å…‰åº¦éŸ¿æ‡‰
        lux_r, lux_g, lux_b, lux_total = luminance(image, film)
        
        # 6. æ‡‰ç”¨å…‰å­¸è™•ç†
        final_image = optical_processing(lux_r, lux_g, lux_b, lux_total, film, grain_style, tone_style)
        
        # 7. ç”Ÿæˆè¼¸å‡ºæ–‡ä»¶å
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        output_path = f"phos_{film_type.lower()}_{timestamp}.jpg"
        
        process_time = time.time() - start_time
        
        return final_image, process_time, output_path
        
    except ValueError as e:
        raise e
    except Exception as e:
        raise ValueError(f"è™•ç†åœ–åƒæ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")


# ==================== Streamlit ç•Œé¢ ====================

# åˆå§‹åŒ– session state
if 'processing_mode' not in st.session_state:
    st.session_state.processing_mode = "å–®å¼µè™•ç†"
if 'batch_results' not in st.session_state:
    st.session_state.batch_results = []

# å‰µå»ºå´é‚Šæ¬„
with st.sidebar:
    # æ‡‰ç”¨æ¨™é¡Œ
    st.markdown("# Phos.")
    st.markdown("## è¨ˆç®—å…‰å­¸èƒ¶ç‰‡æ¨¡æ‹Ÿ")
    st.markdown("---")
    st.markdown("#### ğŸš€ v0.2.0 Â· Batch Processing")
    st.markdown("")
    
    # è™•ç†æ¨¡å¼é¸æ“‡
    st.markdown("### ğŸ“· è™•ç†æ¨¡å¼")
    processing_mode = st.radio(
        "é¸æ“‡è™•ç†æ¨¡å¼",
        ["å–®å¼µè™•ç†", "æ‰¹é‡è™•ç†"],
        index=0,
        help="å–®å¼µè™•ç†: è™•ç†ä¸€å¼µç…§ç‰‡\næ‰¹é‡è™•ç†: åŒæ™‚è™•ç†å¤šå¼µç…§ç‰‡",
        label_visibility="collapsed"
    )
    st.session_state.processing_mode = processing_mode
    
    st.markdown("---")
    st.markdown("### ğŸï¸ èƒ¶ç‰‡è¨­å®š")
    
    # èƒ¶ç‰‡é¡å‹é¸æ“‡
    film_type = st.selectbox(
        "è«‹é¸æ“‡èƒ¶ç‰‡:",
        ["NC200", "Portra400", "Ektar100", "AS100", "HP5Plus400", "Cinestill800T", "FS200"],
        index=0,
        help='''é¸æ“‡è¦æ¨¡æ“¬çš„èƒ¶ç‰‡é¡å‹:

        === å½©è‰²èƒ¶ç‰‡ ===
        NC200: éˆæ„Ÿä¾†è‡ªå¯Œå£« C200ï¼Œç¶“å…¸å¯Œå£«è‰²èª¿
        Portra400: ğŸ†• äººåƒç‹è€…ï¼Œç´°è†©è†šè‰²ï¼Œä½é¡†ç²’ï¼ˆéˆæ„Ÿä¾†è‡ª Kodak Portra 400ï¼‰
        Ektar100: ğŸ†• é¢¨æ™¯åˆ©å™¨ï¼Œé«˜é£½å’Œï¼Œæ¥µç´°é¡†ç²’ï¼ˆéˆæ„Ÿä¾†è‡ª Kodak Ektar 100ï¼‰
        Cinestill800T: ğŸ†• é›»å½±æ„Ÿï¼Œå¼·å…‰æšˆï¼Œæº«æš–è‰²èª¿ï¼ˆéˆæ„Ÿä¾†è‡ª CineStill 800Tï¼‰

        === é»‘ç™½èƒ¶ç‰‡ ===
        AS100: éˆæ„Ÿä¾†è‡ªå¯Œå£« ACROSï¼Œç°éšç´°è†©ï¼Œé¡†ç²’æŸ”å’Œ
        HP5Plus400: ğŸ†• ç¶“å…¸é»‘ç™½ï¼Œæ˜é¡¯é¡†ç²’ï¼Œé«˜å°æ¯”ï¼ˆéˆæ„Ÿä¾†è‡ª Ilford HP5 Plus 400ï¼‰
        FS200: é«˜å°æ¯”åº¦é»‘ç™½æ­£ç‰‡ï¼ˆåŸç†é©—è­‰æ¨¡å‹ï¼‰
        '''
    )

    grain_style = st.selectbox(
        "èƒ¶ç‰‡é¡†ç²’åº¦ï¼š",
        ["é»˜èª", "æŸ”å’Œ", "è¼ƒç²—", "ä¸ä½¿ç”¨"],
        index=0,
        help="é¸æ“‡èƒ¶ç‰‡çš„é¡†ç²’åº¦",
    )
    
    tone_style = st.selectbox(
        "æ›²ç·šæ˜ å°„ï¼š",
        ["filmic", "reinhard"],
        index=0,
        help='''é¸æ“‡Tone mappingæ–¹å¼:
        
        ç›®å‰ç‰ˆæœ¬ä¸‹Reinhardæ¨¡å‹ä¼¼ä¹è¡¨ç¾å‡ºæ›´å¥½çš„å‹•æ…‹ç¯„åœï¼Œ
        filmicæ¨¡å‹å°šä¸å¤ å®Œå–„,ä½†å°è‚©éƒ¨è¶¾éƒ¨æœ‰æ›´ç¬¦åˆç›®æ¨™çš„åˆ»ç•«'''
    )

    st.success(f"å·²é¸æ“‡èƒ¶ç‰‡: {film_type}")
    
    st.divider()
    
    # æ ¹æ“šè™•ç†æ¨¡å¼é¡¯ç¤ºä¸åŒçš„æ–‡ä»¶ä¸Šå‚³å™¨
    if processing_mode == "å–®å¼µè™•ç†":
        uploaded_image = st.file_uploader(
            "é¸æ“‡ä¸€å¼µç…§ç‰‡ä¾†é–‹å§‹æ²–æ´—",
            type=["jpg", "jpeg", "png"],
            help="ä¸Šå‚³ä¸€å¼µç…§ç‰‡æ²–æ´—è©¦è©¦çœ‹å§"
        )
        uploaded_images = None
    else:  # æ‰¹é‡è™•ç†
        uploaded_images = st.file_uploader(
            "é¸æ“‡å¤šå¼µç…§ç‰‡é€²è¡Œæ‰¹é‡è™•ç†",
            type=["jpg", "jpeg", "png"],
            accept_multiple_files=True,
            help="ä¸€æ¬¡æœ€å¤šå¯è™•ç† 50 å¼µç…§ç‰‡"
        )
        uploaded_image = None
        
        if uploaded_images:
            num_files = len(uploaded_images)
            is_valid, error_msg = validate_batch_size(num_files, max_size=50)
            
            if not is_valid:
                st.error(error_msg)
                uploaded_images = None
            else:
                st.info(f"âœ… å·²ä¸Šå‚³ {num_files} å¼µç…§ç‰‡")
                est_time = estimate_processing_time(num_files, avg_time_per_image=2.0)
                st.info(f"â±ï¸ é è¨ˆè™•ç†æ™‚é–“: {est_time}")

# ==================== ä¸»å€åŸŸ ====================

# å–®å¼µè™•ç†æ¨¡å¼
if processing_mode == "å–®å¼µè™•ç†" and uploaded_image is not None:
    try:
        # è™•ç†åœ–åƒ
        film_image, process_time, output_path = process_image(
            uploaded_image, film_type, grain_style, tone_style
        )
        
        # é¡¯ç¤ºçµæœ
        st.image(film_image, channels="BGR", use_container_width=True)
        st.success(f"åº•ç‰‡é¡¯å½±å¥½äº†ï¼Œç”¨æ™‚ {process_time:.2f}ç§’") 
        
        # æ·»åŠ ä¸‹è¼‰æŒ‰éˆ•
        # å°‡ BGR è½‰æ›ç‚º RGB ä¾› PIL ä½¿ç”¨
        film_rgb = cv2.cvtColor(film_image, cv2.COLOR_BGR2RGB)
        film_pil = Image.fromarray(film_rgb)
        
        buf = io.BytesIO()
        film_pil.save(buf, format="JPEG", quality=95)
        byte_im = buf.getvalue()
        
        st.download_button(
            label="ğŸ“¥ ä¸‹è¼‰é«˜æ¸…åœ–åƒ",
            data=byte_im,
            file_name=output_path,
            mime="image/jpeg"
        )
        
    except ValueError as e:
        st.error(f"âŒ éŒ¯èª¤: {str(e)}")
    except Exception as e:
        st.error(f"âŒ æœªé æœŸçš„éŒ¯èª¤: {str(e)}")
        st.error("è«‹å˜—è©¦é‡æ–°ä¸Šå‚³åœ–åƒæˆ–é¸æ“‡å…¶ä»–èƒ¶ç‰‡é¡å‹")

# æ‰¹é‡è™•ç†æ¨¡å¼
elif processing_mode == "æ‰¹é‡è™•ç†" and uploaded_images is not None and len(uploaded_images) > 0:
    st.header(f"ğŸ“¦ æ‰¹é‡è™•ç† - {len(uploaded_images)} å¼µç…§ç‰‡")
    
    # é–‹å§‹è™•ç†æŒ‰éˆ•
    if st.button("ğŸš€ é–‹å§‹æ‰¹é‡è™•ç†", type="primary", use_container_width=True):
        try:
            # åˆå§‹åŒ–æ‰¹é‡è™•ç†å™¨
            batch_processor = BatchProcessor(max_workers=4)
            
            # ç²å–èƒ¶ç‰‡é…ç½®
            film = get_cached_film_profile(film_type)
            
            # å‰µå»ºé€²åº¦æ¢å’Œç‹€æ…‹æ–‡æœ¬
            progress_bar = st.progress(0)
            status_text = st.empty()
            time_text = st.empty()
            
            # é€²åº¦å›èª¿å‡½æ•¸
            def update_progress(current, total, filename):
                progress = current / total
                progress_bar.progress(progress)
                status_text.text(f"è™•ç†ä¸­: {filename} ({current}/{total})")
            
            # å®šç¾©è™•ç†å‡½æ•¸ï¼ˆå°‡ process_image é‚è¼¯å°è£ï¼‰
            def batch_process_func(image_array, film_profile, settings):
                """æ‰¹é‡è™•ç†å–®å¼µåœ–åƒçš„åŒ…è£å‡½æ•¸"""
                # æ¨™æº–åŒ–
                image_std = standardize(image_array)
                
                # è¨ˆç®—å…‰åº¦
                lux_r, lux_g, lux_b, lux_total = luminance(image_std, film_profile)
                
                # å…‰å­¸è™•ç†
                result = optical_processing(
                    lux_r, lux_g, lux_b, lux_total,
                    film_profile,
                    settings['grain_style'],
                    settings['tone_style']
                )
                
                return result
            
            # æº–å‚™è¨­å®š
            settings = {
                'grain_style': grain_style,
                'tone_style': tone_style
            }
            
            # é–‹å§‹è™•ç†
            start_time = time.time()
            
            # ä½¿ç”¨é †åºè™•ç†ï¼ˆThreadPoolExecutor åœ¨ Streamlit ä¸­æ›´ç©©å®šï¼‰
            results = batch_processor.process_batch_sequential(
                uploaded_images,
                film,
                batch_process_func,
                settings,
                progress_callback=update_progress
            )
            
            total_time = time.time() - start_time
            
            # é¡¯ç¤ºçµæœçµ±è¨ˆ
            success_count = sum(1 for r in results if r.success)
            fail_count = len(results) - success_count
            
            progress_bar.empty()
            status_text.empty()
            
            if success_count > 0:
                st.success(f"âœ… è™•ç†å®Œæˆï¼æˆåŠŸ: {success_count}/{len(results)} å¼µï¼Œç¸½ç”¨æ™‚: {total_time:.2f} ç§’")
                
                # ä¿å­˜çµæœåˆ° session state
                st.session_state.batch_results = results
                
                # é¡¯ç¤ºè™•ç†çµæœé è¦½ï¼ˆå‰6å¼µï¼‰
                st.subheader("ğŸ“¸ è™•ç†çµæœé è¦½")
                cols = st.columns(3)
                preview_count = min(6, success_count)
                preview_idx = 0
                
                for idx, result in enumerate(results):
                    if result.success and preview_idx < preview_count:
                        col = cols[preview_idx % 3]
                        with col:
                            # è½‰æ› BGR åˆ° RGB é¡¯ç¤º
                            result_rgb = cv2.cvtColor(result.image_data, cv2.COLOR_BGR2RGB)
                            st.image(result_rgb, caption=result.filename, use_container_width=True)
                            st.caption(f"â±ï¸ {result.processing_time:.2f}s")
                        preview_idx += 1
                
                if success_count > preview_count:
                    st.info(f"é‚„æœ‰ {success_count - preview_count} å¼µç…§ç‰‡æœªé¡¯ç¤ºï¼Œè«‹ä¸‹è¼‰ ZIP æŸ¥çœ‹å…¨éƒ¨")
                
                # å‰µå»º ZIP ä¸‹è¼‰
                st.subheader("ğŸ“¦ ä¸‹è¼‰è™•ç†çµæœ")
                
                with st.spinner("æ­£åœ¨ç”Ÿæˆ ZIP æª”æ¡ˆ..."):
                    zip_data = create_zip_archive(
                        results,
                        film_name=film_type,
                        output_format="jpg",
                        quality=95
                    )
                    zip_filename = generate_zip_filename(film_type)
                
                st.download_button(
                    label=f"ğŸ“¥ ä¸‹è¼‰å…¨éƒ¨ç…§ç‰‡ (ZIP)",
                    data=zip_data,
                    file_name=zip_filename,
                    mime="application/zip",
                    use_container_width=True
                )
                
                # é¡¯ç¤ºå¤±æ•—åˆ—è¡¨ï¼ˆå¦‚æœæœ‰ï¼‰
                if fail_count > 0:
                    with st.expander(f"âš ï¸ {fail_count} å¼µç…§ç‰‡è™•ç†å¤±æ•—", expanded=False):
                        for result in results:
                            if not result.success:
                                st.error(f"âŒ {result.filename}: {result.error_message}")
            else:
                st.error("âŒ æ‰€æœ‰ç…§ç‰‡è™•ç†å¤±æ•—ï¼Œè«‹æª¢æŸ¥åœ–åƒæ ¼å¼æˆ–èƒ¶ç‰‡è¨­å®š")
                
        except Exception as e:
            st.error(f"âŒ æ‰¹é‡è™•ç†æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
            import traceback
            st.error(traceback.format_exc())

# æœªä¸Šå‚³æ–‡ä»¶æ™‚çš„æ­¡è¿ç•Œé¢
else:
    # æ­¡è¿æ¨™é¡Œ
    st.markdown("""
    <div style='text-align: center; padding: 2rem 0 3rem 0;'>
        <h1 style='font-size: 3.5rem; font-weight: 700; margin: 0 0 0.5rem 0;
                   color: #FF6B6B;'>
            Phos.
        </h1>
        <p style='font-size: 1.2rem; color: #B8B8B8; margin: 0 0 0.25rem 0;'>
            è¨ˆç®—å…‰å­¸èƒ¶ç‰‡æ¨¡æ‹Ÿ
        </p>
        <p style='font-size: 1rem; color: #888; font-style: italic; margin: 0;'>
            "No LUTs, we calculate LUX."
        </p>
    </div>
    """, unsafe_allow_html=True)
    
    # åŠŸèƒ½å¡ç‰‡
    col1, col2 = st.columns(2, gap="medium")
    
    with col1:
        st.markdown("""
        <div style='padding: 1.5rem; background: rgba(26, 31, 46, 0.5); 
                    border-radius: 12px; border: 1px solid rgba(255, 107, 107, 0.2);
                    min-height: 200px;'>
            <h3 style='color: #FF6B6B; margin: 0 0 1rem 0; font-size: 1.1rem;'>ğŸï¸ å–®å¼µè™•ç†</h3>
            <ul style='color: #B8B8B8; line-height: 1.8; margin: 0; padding-left: 1.25rem;'>
                <li>ç²¾æº–æ¨¡æ“¬ 7 æ¬¾ç¶“å…¸èƒ¶ç‰‡</li>
                <li>è¨ˆç®—å…‰å­¸åŸç†ï¼Œé LUT</li>
                <li>ç´°è†©é¡†ç²’èˆ‡å…‰æšˆæ•ˆæœ</li>
                <li>é«˜è³ªé‡è¼¸å‡º (JPEG 95)</li>
            </ul>
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        st.markdown("""
        <div style='padding: 1.5rem; background: rgba(26, 31, 46, 0.5); 
                    border-radius: 12px; border: 1px solid rgba(255, 107, 107, 0.2);
                    min-height: 200px;'>
            <h3 style='color: #FF6B6B; margin: 0 0 1rem 0; font-size: 1.1rem;'>ğŸ“¦ æ‰¹é‡è™•ç†</h3>
            <ul style='color: #B8B8B8; line-height: 1.8; margin: 0; padding-left: 1.25rem;'>
                <li>ä¸€æ¬¡è™•ç†æœ€å¤š 50 å¼µç…§ç‰‡</li>
                <li>å¯¦æ™‚é€²åº¦é¡¯ç¤º</li>
                <li>æ™ºèƒ½æ™‚é–“é ä¼°</li>
                <li>ä¸€éµ ZIP æ‰¹é‡ä¸‹è¼‰</li>
            </ul>
        </div>
        """, unsafe_allow_html=True)
    
    st.markdown("<br>", unsafe_allow_html=True)
    
    # èƒ¶ç‰‡åˆ—è¡¨
    st.markdown("### ğŸ¬ å¯ç”¨èƒ¶ç‰‡")
    
    col1, col2 = st.columns(2, gap="medium")
    
    with col1:
        st.markdown("""
        <div style='background: rgba(26, 31, 46, 0.3); padding: 1rem; border-radius: 8px;'>
            <p style='color: #E8E8E8; font-weight: 600; margin: 0 0 0.75rem 0;'>å½©è‰²èƒ¶ç‰‡ Color Films</p>
            <ul style='color: #B8B8B8; line-height: 1.8; margin: 0; padding-left: 1.25rem;'>
                <li><strong>NC200</strong> - å¯Œå£«æ¸…æ–°è‰²èª¿</li>
                <li><strong>Portra400</strong> - äººåƒä½é¡†ç²’</li>
                <li><strong>Ektar100</strong> - é¢¨æ™¯é«˜é£½å’Œ</li>
                <li><strong>Cinestill800T</strong> - é›»å½±å¼·å…‰æšˆ</li>
            </ul>
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        st.markdown("""
        <div style='background: rgba(26, 31, 46, 0.3); padding: 1rem; border-radius: 8px;'>
            <p style='color: #E8E8E8; font-weight: 600; margin: 0 0 0.75rem 0;'>é»‘ç™½èƒ¶ç‰‡ B&W Films</p>
            <ul style='color: #B8B8B8; line-height: 1.8; margin: 0; padding-left: 1.25rem;'>
                <li><strong>AS100</strong> - ç´°è†©ç°éš</li>
                <li><strong>HP5Plus400</strong> - è¡—æ‹ç¶“å…¸</li>
                <li><strong>FS200</strong> - é«˜å°æ¯”æ¦‚å¿µç‰‡</li>
            </ul>
        </div>
        """, unsafe_allow_html=True)
    
    st.markdown("<br><br>", unsafe_allow_html=True)
    
    # ä½¿ç”¨æç¤º
    st.info("ğŸ‘ˆ è«‹åœ¨å·¦å´é‚Šæ¬„é¸æ“‡è™•ç†æ¨¡å¼ä¸¦ä¸Šå‚³ç…§ç‰‡é–‹å§‹ä½¿ç”¨")
