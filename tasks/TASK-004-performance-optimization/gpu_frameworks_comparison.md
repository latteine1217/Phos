# GPU æ¡†æ¶æ·±åº¦æ¯”è¼ƒï¼šPyTorch vs JAX vs OpenCV CUDA

**å‰µå»ºæ™‚é–“**: 2025-12-20  
**åˆ†æè€…**: Main Agent  
**ç›®æ¨™**: ç‚º Phos é¸æ“‡æœ€é©åˆçš„ GPU åŠ é€Ÿæ–¹æ¡ˆ

---

## ğŸ“Š Executive Summary

### ä¸€å¥è©±æ¨è–¦

> **CuPy** ä¾ç„¶æ˜¯æœ€ä½³é¸æ“‡ï¼ˆAPI ç›¸å®¹æ€§ + æ•ˆèƒ½ + ç°¡æ½”æ€§ï¼‰ï¼Œä½†æœ¬æ–‡æª”æ·±å…¥æ¢è¨ä¸‰ç¨®æ›¿ä»£æ–¹æ¡ˆçš„å„ªåŠ£ã€‚

### æ€§èƒ½å°æ¯”è¡¨ï¼ˆé æ¸¬ï¼‰

| æ¡†æ¶ | é æœŸåŠ é€Ÿ | å®‰è£é›£åº¦ | API ç›¸å®¹æ€§ | ä¾è³´å¤§å° | æ¨è–¦åº¦ |
|------|---------|---------|-----------|---------|--------|
| **CuPy** | 8-10x | â­â­â­â­â­ æ˜“ | â­â­â­â­â­ NumPy-like | 200MB | â­â­â­â­â­ |
| **PyTorch** | 6-8x | â­â­â­â­â­ æ˜“ | â­â­â­ éœ€è½‰æ› | 2GB | â­â­â­â­ |
| **JAX** | 10-12x | â­â­â­ ä¸­ | â­â­â­â­ NumPy-like | 500MB | â­â­â­â­ |
| **OpenCV CUDA** | 6-8x | â­ é›£ | â­â­â­â­ OpenCV-like | 0MB (ç·¨è­¯) | â­â­ |

### æœ€çµ‚å»ºè­°æ’åº

1. **ğŸ¥‡ CuPy** (ä¿æŒåŸæ¨è–¦ï¼Œæœ¬æ–‡ä¸æ·±å…¥)
2. **ğŸ¥ˆ JAX** (æœ€é«˜æ•ˆèƒ½ï¼Œé©åˆç ”ç©¶/å¯¦é©—æ€§å°ˆæ¡ˆ)
3. **ğŸ¥‰ PyTorch** (ç”Ÿæ…‹ç³»çµ±æœ€æˆç†Ÿï¼Œé©åˆæ“´å±•æ·±åº¦å­¸ç¿’)
4. **4ï¸âƒ£ OpenCV CUDA** (åƒ…ç•¶å·²æœ‰ç·¨è­¯ç’°å¢ƒæ™‚è€ƒæ…®)

---

## 1ï¸âƒ£ PyTorch: æ·±åº¦å­¸ç¿’æ¡†æ¶çš„ GPU åŠ é€Ÿ

### æ¦‚è¿°

**PyTorch** æ˜¯ Metaï¼ˆFacebookï¼‰é–‹ç™¼çš„æ·±åº¦å­¸ç¿’æ¡†æ¶ï¼Œæ“æœ‰æœ€æˆç†Ÿçš„ GPU åŠ é€Ÿç”Ÿæ…‹ç³»çµ±ã€‚

**æ ¸å¿ƒå„ªå‹¢**:
- âœ… è‡ªå‹•è¨˜æ†¶é«”ç®¡ç†ï¼ˆGPU è¨˜æ†¶é«”æ± ï¼‰
- âœ… è±å¯Œçš„å·ç©é‹ç®—å­ï¼ˆ`torch.nn.functional`ï¼‰
- âœ… æ˜“æ–¼å®‰è£ï¼ˆ`pip install torch`ï¼Œè‡ªå¸¶ CUDA runtimeï¼‰
- âœ… æœªä¾†æ“´å±•æ€§ï¼ˆå¯è¨“ç·´æ¿¾é¡ã€ç¥ç¶“ç¶²è·¯è† ç‰‡æ¨¡å‹ï¼‰

**æ ¸å¿ƒåŠ£å‹¢**:
- âŒ API èˆ‡ NumPy å·®ç•°å¤§ï¼ˆéœ€è¦ 4D tensor: `(N,C,H,W)`ï¼‰
- âŒ ä¾è³´é¾å¤§ï¼ˆ~2GB å®‰è£åŒ…ï¼‰
- âš ï¸ è‡ªå‹•å¾®åˆ†é–‹éŠ·ï¼ˆéœ€æ‰‹å‹•é—œé–‰ `with torch.no_grad()`ï¼‰

---

### å®‰è£æŒ‡å—

#### Linux / Windows (CUDA 11.8)

```bash
# CUDA ç‰ˆæœ¬ï¼ˆæ¨è–¦ï¼‰
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118

# é©—è­‰å®‰è£
python3 -c "import torch; print(f'CUDA available: {torch.cuda.is_available()}')"
```

#### macOS (åƒ… CPUï¼Œæˆ– MPS åŠ é€Ÿ)

```bash
# CPU ç‰ˆæœ¬
pip install torch torchvision

# M1/M2 Mac å¯ä½¿ç”¨ MPS (Metal Performance Shaders)
python3 -c "import torch; print(f'MPS available: {torch.backends.mps.is_available()}')"
```

**é ç·¨è­¯åŒ…å¤§å°**:
- CUDA ç‰ˆæœ¬: ~2.0 GB
- CPU ç‰ˆæœ¬: ~800 MB

---

### API æ•™ç¨‹ï¼šå¾ NumPy åˆ° PyTorch

#### æ ¸å¿ƒæ¦‚å¿µ

| æ¦‚å¿µ | NumPy | PyTorch |
|------|-------|---------|
| **é™£åˆ—é¡å‹** | `np.ndarray` | `torch.Tensor` |
| **è³‡æ–™å‹åˆ¥** | `np.float32` | `torch.float32` |
| **è£ç½®** | CPU å›ºå®š | `cpu` / `cuda:0` / `mps` |
| **å½¢ç‹€** | `(H, W)` | `(H, W)` æˆ– `(N, C, H, W)` |

#### é—œéµå·®ç•°ï¼š4D Tensor è¦æ±‚

PyTorch çš„å·ç©é‹ç®—å­éœ€è¦ 4D tensor:
- `N`: Batch sizeï¼ˆæ‰¹æ¬¡å¤§å°ï¼‰
- `C`: Channelsï¼ˆé€šé“æ•¸ï¼‰
- `H`: Heightï¼ˆé«˜åº¦ï¼‰
- `W`: Widthï¼ˆå¯¬åº¦ï¼‰

**è½‰æ›æµç¨‹**:
```python
# NumPy: (H, W) å–®é€šé“ç°éšå½±åƒ
image_np = np.random.rand(2000, 3000).astype(np.float32)

# PyTorch: (H, W) â†’ (1, 1, H, W)
image_torch = torch.from_numpy(image_np).unsqueeze(0).unsqueeze(0)
# å½¢ç‹€: (2000, 3000) â†’ (1, 1, 2000, 3000)
```

---

### ç¨‹å¼ç¢¼ç¯„ä¾‹ï¼šPyTorch å·ç©

#### ç¯„ä¾‹ 1: åŸºæœ¬å·ç©

```python
import torch
import torch.nn.functional as F
import numpy as np

def convolve_pytorch(image_np: np.ndarray, kernel_np: np.ndarray) -> np.ndarray:
    """
    ä½¿ç”¨ PyTorch é€²è¡Œ GPU åŠ é€Ÿå·ç©
    
    Args:
        image_np: NumPy é™£åˆ— (H, W), float32
        kernel_np: å·ç©æ ¸ (kH, kW), float32
        
    Returns:
        result_np: å·ç©çµæœ (H, W), float32
    """
    # 1. æª¢æŸ¥ GPU å¯ç”¨æ€§
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    # 2. NumPy â†’ Torch (CPU)
    # (H, W) â†’ (1, 1, H, W)
    image_t = torch.from_numpy(image_np).unsqueeze(0).unsqueeze(0)
    
    # (kH, kW) â†’ (1, 1, kH, kW)
    kernel_t = torch.from_numpy(kernel_np).unsqueeze(0).unsqueeze(0)
    
    # 3. å‚³è¼¸åˆ° GPU
    image_t = image_t.to(device)
    kernel_t = kernel_t.to(device)
    
    # 4. å·ç©é‹ç®—ï¼ˆé—œé–‰è‡ªå‹•å¾®åˆ†ä»¥æå‡æ•ˆèƒ½ï¼‰
    with torch.no_grad():
        # padding='same' æ¨¡å¼ï¼ˆPyTorch 1.9+ï¼‰
        kh, kw = kernel_np.shape
        padding = (kh // 2, kw // 2)
        
        result_t = F.conv2d(
            image_t, 
            kernel_t, 
            padding=padding,
            # æ³¨æ„: PyTorch æ²’æœ‰ 'reflect' padding in conv2d
            # éœ€è¦æ‰‹å‹•è™•ç†
        )
    
    # 5. GPU â†’ CPU â†’ NumPy
    result_np = result_t.squeeze().cpu().numpy()
    
    return result_np
```

#### ç¯„ä¾‹ 2: è™•ç†é‚Šç•Œæ¨¡å¼ï¼ˆReflect Paddingï¼‰

PyTorch çš„ `F.conv2d` ä¸æ”¯æ´ `reflect` paddingï¼Œéœ€æ‰‹å‹•è™•ç†ï¼š

```python
def convolve_pytorch_reflect(image_np: np.ndarray, kernel_np: np.ndarray) -> np.ndarray:
    """
    PyTorch å·ç© + Reflect é‚Šç•Œ
    
    ç‰©ç†éœ€æ±‚: é‚Šç•Œéœ€ä½¿ç”¨ reflect æ¨¡å¼ï¼ˆèˆ‡ OpenCV ä¸€è‡´ï¼‰
    """
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    # 1. NumPy â†’ Torch
    image_t = torch.from_numpy(image_np).unsqueeze(0).unsqueeze(0).to(device)
    kernel_t = torch.from_numpy(kernel_np).unsqueeze(0).unsqueeze(0).to(device)
    
    # 2. Reflect paddingï¼ˆæ‰‹å‹•ï¼‰
    kh, kw = kernel_np.shape
    pad_h, pad_w = kh // 2, kw // 2
    
    # F.pad with 'reflect' mode
    image_padded = F.pad(
        image_t, 
        (pad_w, pad_w, pad_h, pad_h),  # (left, right, top, bottom)
        mode='reflect'
    )
    
    # 3. å·ç©ï¼ˆpadding=0ï¼Œå› ç‚ºå·²æ‰‹å‹• padï¼‰
    with torch.no_grad():
        result_t = F.conv2d(image_padded, kernel_t, padding=0)
    
    # 4. è¿”å› NumPy
    result_np = result_t.squeeze().cpu().numpy()
    
    return result_np
```

#### ç¯„ä¾‹ 3: æ‰¹æ¬¡è™•ç†å„ªåŒ–

PyTorch çš„å¼·é …æ˜¯æ‰¹æ¬¡è™•ç†ï¼š

```python
def convolve_batch_pytorch(images_np: list, kernel_np: np.ndarray) -> list:
    """
    æ‰¹æ¬¡å·ç©ï¼ˆæœ€å¤§åŒ– GPU åˆ©ç”¨ç‡ï¼‰
    
    Args:
        images_np: åˆ—è¡¨ï¼Œæ¯å€‹å…ƒç´ ç‚º (H, W) NumPy é™£åˆ—
        kernel_np: å…±ç”¨å·ç©æ ¸ (kH, kW)
        
    Returns:
        results_np: åˆ—è¡¨ï¼Œå·ç©çµæœ
    """
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    # 1. æ‰¹æ¬¡è½‰æ› (N, 1, H, W)
    images_t = torch.stack([
        torch.from_numpy(img).unsqueeze(0) for img in images_np
    ]).to(device)
    
    # 2. æ ¸è½‰æ› (1, 1, kH, kW)
    kernel_t = torch.from_numpy(kernel_np).unsqueeze(0).unsqueeze(0).to(device)
    
    # 3. æ‰¹æ¬¡å·ç©ï¼ˆä¸€æ¬¡ GPU èª¿ç”¨è™•ç†æ‰€æœ‰å½±åƒï¼‰
    kh, kw = kernel_np.shape
    padding = (kh // 2, kw // 2)
    
    with torch.no_grad():
        results_t = F.conv2d(images_t, kernel_t, padding=padding)
    
    # 4. æ‰¹æ¬¡è¿”å›
    results_np = [r.squeeze().cpu().numpy() for r in results_t]
    
    return results_np
```

---

### è¨˜æ†¶é«”ç®¡ç†

#### GPU è¨˜æ†¶é«”ç›£æ§

```python
def print_gpu_memory():
    """é¡¯ç¤º GPU è¨˜æ†¶é«”ä½¿ç”¨æƒ…æ³"""
    if not torch.cuda.is_available():
        print("GPU ä¸å¯ç”¨")
        return
    
    allocated = torch.cuda.memory_allocated() / 1e9  # GB
    reserved = torch.cuda.memory_reserved() / 1e9
    
    print(f"å·²åˆ†é…: {allocated:.2f} GB")
    print(f"å·²ä¿ç•™: {reserved:.2f} GB")
```

#### è¨˜æ†¶é«”æ¸…ç†

```python
# æ‰‹å‹•æ¸…ç† GPU è¨˜æ†¶é«”
torch.cuda.empty_cache()

# æˆ–åœ¨æ‰¹æ¬¡è™•ç†ä¸­å®šæœŸæ¸…ç†
for i, img in enumerate(images):
    result = process_image(img)
    
    if i % 10 == 0:
        torch.cuda.empty_cache()  # æ¯ 10 å¼µæ¸…ç†ä¸€æ¬¡
```

---

### æ•ˆèƒ½åˆ†æ

#### é æœŸåŠ é€Ÿæ¯”ï¼ˆ2000Ã—3000 å½±åƒï¼Œ201Ã—201 æ ¸ï¼‰

| æ“ä½œ | CPU (OpenCV) | PyTorch GPU | åŠ é€Ÿæ¯” |
|------|-------------|-------------|--------|
| **å–®æ¬¡å·ç©** | 250 ms | 40 ms | **6.25x** |
| **æ‰¹æ¬¡ 10 å¼µ** | 2500 ms | 180 ms | **13.9x** |
| **ç¬¬ä¸€æ¬¡èª¿ç”¨** | 250 ms | 150 ms | 1.67x (JIT ç·¨è­¯) |

#### æ•ˆèƒ½é–‹éŠ·ä¾†æº

1. **å½¢ç‹€è½‰æ›**: `(H,W)` â†’ `(1,1,H,W)` â†’ `(H,W)` (~5ms)
2. **CPUâ†”GPU å‚³è¼¸**: ~10-20ms (å–æ±ºæ–¼å½±åƒå¤§å°)
3. **é¦–æ¬¡èª¿ç”¨**: JIT ç·¨è­¯ + GPU åˆå§‹åŒ– (~100ms)

**çµè«–**: å–®å¼µå½±åƒåŠ é€Ÿæœ‰é™ï¼ˆ6xï¼‰ï¼Œæ‰¹æ¬¡è™•ç†å„ªå‹¢æ˜é¡¯ï¼ˆ14xï¼‰

---

### æ•´åˆåˆ° Phos

#### ä¿®æ”¹ `convolve_adaptive()`

```python
# Phos_0.3.0.py

# é ‚éƒ¨å°å…¥ï¼ˆæ¢ä»¶å¼ï¼‰
try:
    import torch
    import torch.nn.functional as F
    PYTORCH_AVAILABLE = torch.cuda.is_available()
except ImportError:
    PYTORCH_AVAILABLE = False

def convolve_adaptive(image, kernel, method='auto', use_gpu=False, backend='cupy'):
    """
    è‡ªé©æ‡‰å·ç©ï¼ˆæ”¯æ´å¤š GPU å¾Œç«¯ï¼‰
    
    Args:
        backend: 'cupy' | 'pytorch' | 'jax' | 'opencv_cuda'
    """
    if use_gpu and backend == 'pytorch' and PYTORCH_AVAILABLE:
        return convolve_pytorch_reflect(image, kernel)
    elif method == 'auto':
        ksize = kernel.shape[0]
        if ksize > 150:
            return convolve_fft(image, kernel)
        else:
            return cv2.filter2D(image, -1, kernel, borderType=cv2.BORDER_REFLECT)
    # ... å…¶ä»–åˆ†æ”¯
```

---

### PyTorch å„ªç¼ºé»ç¸½çµ

#### âœ… å„ªé»

1. **å®‰è£ç°¡å–®**: `pip install torch` ä¸€è¡Œæå®šï¼ˆè‡ªå¸¶ CUDA runtimeï¼‰
2. **ç”Ÿæ…‹ç³»çµ±**: æœ€æˆç†Ÿçš„æ·±åº¦å­¸ç¿’ç”Ÿæ…‹ï¼ˆtorchvision, timm, transformersï¼‰
3. **æ–‡æª”è±å¯Œ**: å®˜æ–¹æ•™ç¨‹è©³ç´°ï¼Œç¤¾ç¾¤æ´»èº
4. **æ‰¹æ¬¡è™•ç†**: é‡å°æ‰¹æ¬¡é‹ç®—é«˜åº¦å„ªåŒ–
5. **æœªä¾†æ“´å±•**: å¯è¼•é¬†æ•´åˆç¥ç¶“ç¶²è·¯ï¼ˆå¦‚å¯è¨“ç·´çš„è† ç‰‡æ¿¾é¡ï¼‰

#### âŒ ç¼ºé»

1. **API å·®ç•°**: éœ€è¦ 4D tensorï¼Œè½‰æ›æœ‰é–‹éŠ·
2. **ä¾è³´é¾å¤§**: ~2GBï¼ˆå°è¼•é‡å°ˆæ¡ˆè² æ“”é‡ï¼‰
3. **é‚Šç•Œæ¨¡å¼**: `conv2d` ä¸åŸç”Ÿæ”¯æ´ `reflect`ï¼Œéœ€æ‰‹å‹• pad
4. **å–®å¼µå½±åƒ**: å°æ‰¹æ¬¡æ™‚åŠ é€Ÿæœ‰é™ï¼ˆJIT + å‚³è¼¸é–‹éŠ·ï¼‰
5. **macOS GPU**: åƒ… M1/M2 æ”¯æ´ MPSï¼ˆNVIDIA GPU ä¸æ”¯æ´ï¼‰

#### ğŸ¯ é©ç”¨å ´æ™¯

- âœ… æ‰¹æ¬¡è™•ç†ï¼ˆ10+ å¼µå½±åƒï¼‰
- âœ… è¨ˆåŠƒæ“´å±•æ·±åº¦å­¸ç¿’åŠŸèƒ½
- âœ… å·²æœ‰ PyTorch ä¾è³´
- âŒ è¼•é‡ç´šå°ˆæ¡ˆ
- âŒ macOS + NVIDIA GPU ç”¨æˆ¶

---

## 2ï¸âƒ£ JAX: Google çš„é«˜æ•ˆèƒ½è¨ˆç®—æ¡†æ¶

### æ¦‚è¿°

**JAX** æ˜¯ Google é–‹ç™¼çš„ NumPy + è‡ªå‹•å¾®åˆ† + XLA ç·¨è­¯å™¨ï¼Œå°ˆæ³¨æ–¼é«˜æ•ˆèƒ½æ•¸å€¼è¨ˆç®—ã€‚

**æ ¸å¿ƒå„ªå‹¢**:
- âœ… **NumPy-like API**: å¹¾ä¹èˆ‡ NumPy å®Œå…¨ç›¸å®¹
- âœ… **XLA ç·¨è­¯**: è‡ªå‹•å„ªåŒ–è¨ˆç®—åœ–ï¼ˆæ¯” PyTorch æ›´å¿«ï¼‰
- âœ… **ç´”å‡½æ•¸å¼**: ç„¡å‰¯ä½œç”¨ï¼Œæ˜“æ–¼ä¸¦è¡ŒåŒ–
- âœ… **JIT ç·¨è­¯**: `@jax.jit` è£é£¾å™¨ä¸€éµåŠ é€Ÿ

**æ ¸å¿ƒåŠ£å‹¢**:
- âŒ **å­¸ç¿’æ›²ç·š**: å‡½æ•¸å¼ç·¨ç¨‹ç¯„å¼ï¼ˆèˆ‡å‘½ä»¤å¼ä¸åŒï¼‰
- âŒ **æ–‡æª”è¼ƒå°‘**: ç›¸æ¯” PyTorch ç”Ÿæ…‹è¼ƒå°
- âš ï¸ **ç·¨è­¯é–‹éŠ·**: é¦–æ¬¡èª¿ç”¨éœ€ç·¨è­¯ï¼ˆå¯èƒ½å¾ˆæ…¢ï¼‰

---

### å®‰è£æŒ‡å—

#### Linux (CUDA 11.x)

```bash
# CUDA ç‰ˆæœ¬
pip install --upgrade "jax[cuda11_pip]" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html

# é©—è­‰å®‰è£
python3 -c "import jax; print(jax.devices())"
```

#### macOS / Windows (CPU-only)

```bash
# CPU ç‰ˆæœ¬
pip install --upgrade jax jaxlib

# macOS Metal åŠ é€Ÿï¼ˆå¯¦é©—æ€§ï¼‰
# ç›®å‰ä¸ç©©å®šï¼Œä¸æ¨è–¦
```

**ä¾è³´å¤§å°**:
- CUDA ç‰ˆæœ¬: ~500 MB
- CPU ç‰ˆæœ¬: ~200 MB

**æ³¨æ„**: JAX GPU æ”¯æ´ä¸»è¦åœ¨ Linuxï¼ŒWindows/macOS æ”¯æ´æœ‰é™ã€‚

---

### API æ•™ç¨‹ï¼šJAX æ•¸å€¼è¨ˆç®—

#### æ ¸å¿ƒæ¦‚å¿µ

| æ¦‚å¿µ | NumPy | JAX |
|------|-------|-----|
| **é™£åˆ—é¡å‹** | `np.ndarray` | `jax.numpy.ndarray` |
| **å‘½åç©ºé–“** | `numpy` | `jax.numpy` |
| **è£ç½®ç®¡ç†** | ç„¡ | `jax.device_put()` |
| **ç·¨è­¯** | ç„¡ | `@jax.jit` |

#### é—œéµå„ªå‹¢ï¼šNumPy API ç›¸å®¹

```python
import jax.numpy as jnp
import numpy as np

# NumPy ç¨‹å¼ç¢¼
x_np = np.random.rand(100, 100)
y_np = np.sin(x_np) + np.cos(x_np)

# JAX ç¨‹å¼ç¢¼ï¼ˆå¹¾ä¹ç›¸åŒï¼ï¼‰
x_jax = jnp.random.rand(100, 100)
y_jax = jnp.sin(x_jax) + jnp.cos(x_jax)
```

---

### ç¨‹å¼ç¢¼ç¯„ä¾‹ï¼šJAX å·ç©

#### ç¯„ä¾‹ 1: åŸºæœ¬å·ç©ï¼ˆä½¿ç”¨ scipy.signalï¼‰

```python
import jax
import jax.numpy as jnp
from jax.scipy.signal import convolve
import numpy as np

def convolve_jax_simple(image_np: np.ndarray, kernel_np: np.ndarray) -> np.ndarray:
    """
    JAX å·ç©ï¼ˆç°¡å–®ç‰ˆæœ¬ï¼‰
    
    ä½¿ç”¨ jax.scipy.signal.convolveï¼ˆèˆ‡ NumPy ç›¸å®¹ï¼‰
    """
    # 1. NumPy â†’ JAXï¼ˆè‡ªå‹•å‚³åˆ°é è¨­è£ç½®ï¼‰
    image_jax = jnp.array(image_np)
    kernel_jax = jnp.array(kernel_np)
    
    # 2. å·ç©ï¼ˆmode='same' ä¿æŒå°ºå¯¸ï¼‰
    result_jax = convolve(image_jax, kernel_jax, mode='same')
    
    # 3. JAX â†’ NumPy
    result_np = np.array(result_jax)
    
    return result_np
```

**å•é¡Œ**: `jax.scipy.signal.convolve` ä¸æ”¯æ´ `reflect` é‚Šç•Œæ¨¡å¼ï¼

#### ç¯„ä¾‹ 2: ä½¿ç”¨ lax.convï¼ˆé«˜æ•ˆèƒ½ç‰ˆï¼‰

```python
from jax import lax

def convolve_jax_lax(image_np: np.ndarray, kernel_np: np.ndarray) -> np.ndarray:
    """
    JAX å·ç©ï¼ˆä½¿ç”¨ lax.conv_general_dilatedï¼Œæœ€é«˜æ•ˆï¼‰
    
    lax: Low-level APIï¼ŒXLA ç›´æ¥ç·¨è­¯
    """
    # 1. NumPy â†’ JAX
    image_jax = jnp.array(image_np)
    kernel_jax = jnp.array(kernel_np)
    
    # 2. èª¿æ•´å½¢ç‹€ï¼ˆlax.conv éœ€è¦ 4Dï¼‰
    # (H, W) â†’ (1, H, W, 1)  [NHWC format]
    image_4d = image_jax[None, :, :, None]
    
    # (kH, kW) â†’ (kH, kW, 1, 1)  [kernel: (H, W, in_channels, out_channels)]
    kernel_4d = kernel_jax[:, :, None, None]
    
    # 3. å·ç©ï¼ˆä½¿ç”¨ lax.conv_general_dilatedï¼‰
    kh, kw = kernel_np.shape
    padding = ((kh // 2, kh // 2), (kw // 2, kw // 2))
    
    result_4d = lax.conv_general_dilated(
        lhs=image_4d,            # è¼¸å…¥
        rhs=kernel_4d,           # æ ¸
        window_strides=(1, 1),   # æ­¥é•·
        padding=padding,         # å¡«å……
        dimension_numbers=('NHWC', 'HWIO', 'NHWC')  # æ ¼å¼
    )
    
    # 4. èª¿æ•´å› 2D
    result_jax = result_4d[0, :, :, 0]
    
    # 5. JAX â†’ NumPy
    result_np = np.array(result_jax)
    
    return result_np
```

**æ³¨æ„**: `lax.conv` ä¹Ÿä¸æ”¯æ´ `reflect` paddingï¼ˆåƒ… `SAME`/`VALID`ï¼‰

#### ç¯„ä¾‹ 3: æ‰‹å‹• Reflect Padding

```python
def convolve_jax_reflect(image_np: np.ndarray, kernel_np: np.ndarray) -> np.ndarray:
    """
    JAX å·ç© + Reflect é‚Šç•Œï¼ˆæ‰‹å‹•å¯¦ä½œï¼‰
    """
    # 1. NumPy â†’ JAX
    image_jax = jnp.array(image_np)
    kernel_jax = jnp.array(kernel_np)
    
    # 2. Reflect padding
    kh, kw = kernel_np.shape
    pad_h, pad_w = kh // 2, kw // 2
    
    # JAX çš„ pad æ”¯æ´ 'reflect' å—ï¼Ÿæª¢æŸ¥æ–‡æª”...
    # ç­”æ¡ˆ: âŒ jnp.pad åƒ…æ”¯æ´ 'constant', 'edge', 'wrap'
    # éœ€è¦è‡ªè¡Œå¯¦ä½œ reflect paddingï¼
    
    # ç°¡åŒ–æ–¹æ¡ˆ: ä½¿ç”¨ 'edge' (é›–ç„¶ä¸å®Œç¾)
    image_padded = jnp.pad(
        image_jax,
        ((pad_h, pad_h), (pad_w, pad_w)),
        mode='edge'  # é€€è€Œæ±‚å…¶æ¬¡
    )
    
    # 3. ä½¿ç”¨ FFT å·ç©ï¼ˆJAX åŸç”Ÿæ”¯æ´ï¼‰
    # å…ˆè·³é padding å•é¡Œï¼Œå±•ç¤º FFT
    image_fft = jnp.fft.rfft2(image_padded)
    
    # æ ¸å¡«å……ä¸¦å±…ä¸­
    kernel_padded = jnp.zeros_like(image_padded)
    kernel_padded = kernel_padded.at[:kh, :kw].set(kernel_jax)
    kernel_padded = jnp.roll(kernel_padded, (-kh//2, -kw//2), axis=(0, 1))
    
    kernel_fft = jnp.fft.rfft2(kernel_padded)
    
    # å·ç©
    result_fft = image_fft * kernel_fft
    result = jnp.fft.irfft2(result_fft)
    
    # 4. è£å‰ª
    result = result[pad_h:-pad_h, pad_w:-pad_w]
    
    return np.array(result)
```

**å•é¡Œ**: JAX çš„ `jnp.pad` ä¸æ”¯æ´ `reflect` æ¨¡å¼ï¼ˆèˆ‡ Phos ä¸ç›¸å®¹ï¼‰ï¼

---

### JIT ç·¨è­¯ï¼šé€Ÿåº¦çš„ç§˜å¯†æ­¦å™¨

#### ç¯„ä¾‹ï¼š@jax.jit è£é£¾å™¨

```python
import jax
import time

# æœªç·¨è­¯ç‰ˆæœ¬
def convolve_slow(image, kernel):
    return jnp.convolve(image, kernel, mode='same')

# JIT ç·¨è­¯ç‰ˆæœ¬
@jax.jit
def convolve_fast(image, kernel):
    return jnp.convolve(image, kernel, mode='same')

# æ¸¬è©¦
image = jnp.ones(10000)
kernel = jnp.ones(201)

# ç¬¬ä¸€æ¬¡èª¿ç”¨ï¼ˆç·¨è­¯ + åŸ·è¡Œï¼‰
t0 = time.perf_counter()
result1 = convolve_fast(image, kernel).block_until_ready()
compile_time = time.perf_counter() - t0
print(f"ç¬¬ä¸€æ¬¡ï¼ˆç·¨è­¯ï¼‰: {compile_time*1000:.1f} ms")

# ç¬¬äºŒæ¬¡èª¿ç”¨ï¼ˆåƒ…åŸ·è¡Œï¼‰
t0 = time.perf_counter()
result2 = convolve_fast(image, kernel).block_until_ready()
run_time = time.perf_counter() - t0
print(f"ç¬¬äºŒæ¬¡ï¼ˆåŸ·è¡Œï¼‰: {run_time*1000:.1f} ms")

# æœªç·¨è­¯ç‰ˆæœ¬
t0 = time.perf_counter()
result3 = convolve_slow(image, kernel).block_until_ready()
slow_time = time.perf_counter() - t0
print(f"æœªç·¨è­¯: {slow_time*1000:.1f} ms")

print(f"åŠ é€Ÿæ¯”: {slow_time / run_time:.1f}x")
```

**é æœŸè¼¸å‡º**:
```
ç¬¬ä¸€æ¬¡ï¼ˆç·¨è­¯ï¼‰: 523.4 ms
ç¬¬äºŒæ¬¡ï¼ˆåŸ·è¡Œï¼‰: 12.3 ms
æœªç·¨è­¯: 145.2 ms
åŠ é€Ÿæ¯”: 11.8x
```

**é—œéµ**: ç·¨è­¯é–‹éŠ·å¤§ï¼Œä½†å¾ŒçºŒèª¿ç”¨æ¥µå¿«ï¼ˆé©åˆé‡è¤‡é‹ç®—ï¼‰

---

### è£ç½®ç®¡ç†

#### æ‰‹å‹•æŒ‡å®š GPU

```python
# åˆ—å‡ºæ‰€æœ‰è£ç½®
devices = jax.devices()
print(devices)  # [CpuDevice(id=0), GpuDevice(id=0), ...]

# æŒ‡å®š GPU
gpu = jax.devices('gpu')[0]

# å‚³è¼¸åˆ° GPU
image_gpu = jax.device_put(image_jax, gpu)
```

#### å¤š GPU ä¸¦è¡Œï¼ˆé€²éšï¼‰

```python
from jax import pmap

@pmap
def process_parallel(images):
    """åœ¨å¤šå€‹ GPU ä¸Šä¸¦è¡Œè™•ç†"""
    return jnp.sin(images) + jnp.cos(images)

# è‡ªå‹•åˆ†é…åˆ°æ‰€æœ‰ GPU
images = jnp.ones((4, 1000, 1000))  # 4 å¼µå½±åƒ
results = process_parallel(images)  # æ¯å€‹ GPU è™•ç† 1 å¼µ
```

---

### æ•ˆèƒ½åˆ†æ

#### é æœŸåŠ é€Ÿæ¯”ï¼ˆ2000Ã—3000 å½±åƒï¼Œ201Ã—201 æ ¸ï¼‰

| æ“ä½œ | CPU (NumPy) | JAX GPU | åŠ é€Ÿæ¯” |
|------|------------|---------|--------|
| **é¦–æ¬¡èª¿ç”¨** | 250 ms | 800 ms | **0.31x** (ç·¨è­¯æ…¢) |
| **ç¬¬äºŒæ¬¡èª¿ç”¨** | 250 ms | 20 ms | **12.5x** âœ… |
| **æ‰¹æ¬¡ 10 å¼µ** | 2500 ms | 150 ms | **16.7x** âœ… |

**çµè«–**: JAX æ˜¯æœ€å¿«çš„æ–¹æ¡ˆï¼ˆç†è«–ä¸Šï¼‰ï¼Œä½†é¦–æ¬¡ç·¨è­¯é–‹éŠ·å¤§ã€‚

---

### JAX çš„è‡´å‘½å•é¡Œï¼šReflect Padding

#### ç¾ç‹€

```python
# JAX æ”¯æ´çš„ padding æ¨¡å¼
jnp.pad(image, pad_width, mode='constant')  # âœ…
jnp.pad(image, pad_width, mode='edge')      # âœ…
jnp.pad(image, pad_width, mode='wrap')      # âœ…
jnp.pad(image, pad_width, mode='reflect')   # âŒ ä¸æ”¯æ´ï¼
```

#### å½±éŸ¿

Phos çš„æ‰€æœ‰å·ç©éƒ½ä½¿ç”¨ `cv2.BORDER_REFLECT`ï¼ˆåå°„é‚Šç•Œï¼‰ï¼ŒJAX ç„¡æ³•ç›´æ¥ç›¸å®¹ã€‚

#### è§£æ±ºæ–¹æ¡ˆ

1. **æ‰‹å‹•å¯¦ä½œ reflect padding**ï¼ˆè¤‡é›œï¼Œæ•ˆèƒ½æœªçŸ¥ï¼‰
2. **ä½¿ç”¨ 'edge' è¿‘ä¼¼**ï¼ˆç²¾åº¦æå¤±ï¼‰
3. **æ”¾æ£„ JAX**ï¼ˆæœ€å¯¦éš›ï¼‰

**çµè«–**: JAX ä¸é©åˆ Phosï¼ˆé‚Šç•Œæ¨¡å¼ä¸ç›¸å®¹ï¼‰

---

### JAX å„ªç¼ºé»ç¸½çµ

#### âœ… å„ªé»

1. **æœ€é«˜æ•ˆèƒ½**: XLA ç·¨è­¯å™¨å„ªåŒ–ï¼Œç†è«–æœ€å¿«ï¼ˆ12-17xï¼‰
2. **NumPy ç›¸å®¹**: API å¹¾ä¹å®Œå…¨ç›¸åŒï¼ˆé™¤äº† paddingï¼‰
3. **ç´”å‡½æ•¸å¼**: æ˜“æ–¼æ¸¬è©¦ã€é™¤éŒ¯ã€ä¸¦è¡ŒåŒ–
4. **JIT ç·¨è­¯**: è‡ªå‹•å„ªåŒ–è¨ˆç®—åœ–
5. **å‰æ²¿ç ”ç©¶**: Google å…§éƒ¨ä½¿ç”¨ï¼ˆDeepMind, Brainï¼‰

#### âŒ ç¼ºé»

1. **ç·¨è­¯é–‹éŠ·**: é¦–æ¬¡èª¿ç”¨æ…¢ï¼ˆ800msï¼‰
2. **é‚Šç•Œæ¨¡å¼**: âŒ ä¸æ”¯æ´ `reflect`ï¼ˆèˆ‡ Phos ä¸ç›¸å®¹ï¼‰
3. **å­¸ç¿’æ›²ç·š**: å‡½æ•¸å¼ç·¨ç¨‹ç¯„å¼ï¼ˆå‰¯ä½œç”¨å—é™ï¼‰
4. **ç”Ÿæ…‹è¼ƒå°**: ç›¸æ¯” PyTorch æ–‡æª”å°‘
5. **å¹³å°é™åˆ¶**: GPU æ”¯æ´ä¸»è¦åœ¨ Linux

#### ğŸ¯ é©ç”¨å ´æ™¯

- âœ… ç ”ç©¶/å¯¦é©—æ€§å°ˆæ¡ˆï¼ˆé¡˜æ„å¦¥å”é‚Šç•Œæ¨¡å¼ï¼‰
- âœ… æ‰¹æ¬¡è™•ç†ï¼ˆç·¨è­¯ä¸€æ¬¡ï¼ŒåŸ·è¡Œå¤šæ¬¡ï¼‰
- âœ… Linux + NVIDIA GPU ç’°å¢ƒ
- âŒ éœ€è¦ `reflect` é‚Šç•Œçš„å°ˆæ¡ˆï¼ˆå¦‚ Phosï¼‰
- âŒ Windows/macOS ç”¨æˆ¶

---

## 3ï¸âƒ£ OpenCV CUDA: åŸç”Ÿ GPU æ”¯æ´

### æ¦‚è¿°

**OpenCV CUDA** æ˜¯ OpenCV çš„ GPU åŠ é€Ÿæ¨¡çµ„ï¼Œæ”¯æ´ CUDAã€OpenCLã€Vulkan å¤šç¨®å¾Œç«¯ã€‚

**æ ¸å¿ƒå„ªå‹¢**:
- âœ… **åŸç”Ÿæ•´åˆ**: ç„¡é¡å¤– Python ä¾è³´
- âœ… **API ç›¸ä¼¼**: `cv2.cuda.*` èˆ‡ `cv2.*` çµæ§‹ç›¸ä¼¼
- âœ… **å¤šå¾Œç«¯**: CUDA (NVIDIA) / OpenCL (AMD) / Vulkan (é€šç”¨)

**æ ¸å¿ƒåŠ£å‹¢**:
- âŒ **ç·¨è­¯è¤‡é›œ**: éœ€å¾æºç¢¼ç·¨è­¯ï¼ˆç„¡é ç·¨è­¯è¼ªï¼‰
- âŒ **æ–‡æª”ç¼ºä¹**: å®˜æ–¹æ–‡æª”è¼ƒå°‘ï¼Œç¯„ä¾‹æœ‰é™
- âš ï¸ **åŠŸèƒ½å—é™**: éƒ¨åˆ† CPU å‡½æ•¸ç„¡ GPU å°æ‡‰

---

### å®‰è£æŒ‡å—

#### æ–¹æ¡ˆ A: å¾æºç¢¼ç·¨è­¯ï¼ˆLinuxï¼‰

```bash
# 1. å®‰è£ä¾è³´
sudo apt-get install build-essential cmake git
sudo apt-get install libgtk-3-dev pkg-config
sudo apt-get install nvidia-cuda-toolkit  # CUDA

# 2. ä¸‹è¼‰æºç¢¼
git clone https://github.com/opencv/opencv.git
git clone https://github.com/opencv/opencv_contrib.git

# 3. é…ç½®ç·¨è­¯ï¼ˆé—œéµæ­¥é©Ÿï¼‰
cd opencv
mkdir build && cd build

cmake -D CMAKE_BUILD_TYPE=RELEASE \
      -D CMAKE_INSTALL_PREFIX=/usr/local \
      -D OPENCV_EXTRA_MODULES_PATH=../../opencv_contrib/modules \
      -D WITH_CUDA=ON \
      -D CUDA_ARCH_BIN=8.6 \            # æ ¹æ“š GPU æ¶æ§‹èª¿æ•´
      -D CUDA_ARCH_PTX="" \
      -D ENABLE_FAST_MATH=ON \
      -D CUDA_FAST_MATH=ON \
      -D WITH_CUBLAS=ON \
      -D WITH_CUDNN=ON \                # å¦‚æœ‰ cuDNN
      -D OPENCV_DNN_CUDA=ON \
      -D BUILD_opencv_python3=ON \
      -D PYTHON3_EXECUTABLE=$(which python3) \
      ..

# 4. ç·¨è­¯ï¼ˆè€—æ™‚ 30-60 åˆ†é˜ï¼‰
make -j$(nproc)

# 5. å®‰è£
sudo make install
sudo ldconfig

# 6. é©—è­‰
python3 -c "import cv2; print(cv2.cuda.getCudaEnabledDeviceCount())"
```

**CUDA_ARCH_BIN å°ç…§è¡¨**:
| GPU å‹è™Ÿ | æ¶æ§‹ä»£è™Ÿ | CUDA_ARCH_BIN |
|---------|---------|---------------|
| GTX 1060 | Pascal | 6.1 |
| RTX 2080 | Turing | 7.5 |
| RTX 3090 | Ampere | 8.6 |
| RTX 4090 | Ada | 8.9 |

#### æ–¹æ¡ˆ B: Dockerï¼ˆæ¨è–¦ï¼‰

```dockerfile
# Dockerfile
FROM nvidia/cuda:11.8.0-cudnn8-devel-ubuntu22.04

# å®‰è£ OpenCV with CUDA
RUN apt-get update && apt-get install -y \
    python3-opencv \
    # ... (ç·¨è­¯æ­¥é©Ÿçœç•¥)

# å®‰è£ Phos ä¾è³´
COPY requirements.txt /app/
RUN pip install -r /app/requirements.txt
```

```bash
# å»ºæ§‹
docker build -t phos-gpu .

# åŸ·è¡Œ
docker run --gpus all -p 8501:8501 phos-gpu
```

---

### API æ•™ç¨‹ï¼šOpenCV CUDA

#### æ ¸å¿ƒæ¦‚å¿µ

| æ¦‚å¿µ | CPU | GPU |
|------|-----|-----|
| **é™£åˆ—é¡å‹** | `np.ndarray` | `cv2.cuda_GpuMat` |
| **è¨˜æ†¶é«”ä½ç½®** | RAM | VRAM |
| **ä¸Šå‚³** | ç„¡ | `gpu_mat.upload(cpu_array)` |
| **ä¸‹è¼‰** | ç„¡ | `cpu_array = gpu_mat.download()` |

#### é—œéµå·®ç•°ï¼šGpuMat ç‰©ä»¶

```python
import cv2
import numpy as np

# CPU é™£åˆ—
image_cpu = np.random.rand(1000, 1000).astype(np.float32)

# GPU é™£åˆ—
gpu_mat = cv2.cuda_GpuMat()
gpu_mat.upload(image_cpu)

# GPU é‹ç®—
result_gpu = cv2.cuda.filter2D(gpu_mat, -1, kernel)

# ä¸‹è¼‰å› CPU
result_cpu = result_gpu.download()
```

---

### ç¨‹å¼ç¢¼ç¯„ä¾‹ï¼šOpenCV CUDA å·ç©

#### ç¯„ä¾‹ 1: åŸºæœ¬å·ç©

```python
import cv2
import numpy as np

def convolve_opencv_cuda(image_np: np.ndarray, kernel_np: np.ndarray) -> np.ndarray:
    """
    OpenCV CUDA å·ç©
    
    Args:
        image_np: NumPy é™£åˆ— (H, W), float32
        kernel_np: å·ç©æ ¸ (kH, kW), float32
        
    Returns:
        result_np: å·ç©çµæœ (H, W), float32
    """
    # 1. æª¢æŸ¥ CUDA å¯ç”¨æ€§
    if cv2.cuda.getCudaEnabledDeviceCount() == 0:
        raise RuntimeError("No CUDA-enabled device found")
    
    # 2. ä¸Šå‚³åˆ° GPU
    gpu_image = cv2.cuda_GpuMat()
    gpu_image.upload(image_np)
    
    # 3. GPU å·ç©
    gpu_result = cv2.cuda.filter2D(
        gpu_image, 
        ddepth=-1,  # ä¿æŒåŸæ·±åº¦
        kernel=kernel_np,
        borderMode=cv2.BORDER_REFLECT  # âœ… æ”¯æ´ reflectï¼
    )
    
    # 4. ä¸‹è¼‰å› CPU
    result_np = gpu_result.download()
    
    return result_np
```

**å„ªé»**: ç›´æ¥æ”¯æ´ `BORDER_REFLECT`ï¼ˆèˆ‡ CPU ç‰ˆæœ¬ä¸€è‡´ï¼‰ï¼

#### ç¯„ä¾‹ 2: é«˜æ–¯æ¨¡ç³Šï¼ˆå°ˆç”¨å‡½æ•¸ï¼‰

```python
def gaussian_blur_cuda(image_np: np.ndarray, ksize: int, sigma: float) -> np.ndarray:
    """
    GPU åŠ é€Ÿé«˜æ–¯æ¨¡ç³Šï¼ˆä½¿ç”¨ cv2.cuda.GaussianBlurï¼‰
    """
    if cv2.cuda.getCudaEnabledDeviceCount() == 0:
        # Fallback to CPU
        return cv2.GaussianBlur(image_np, (ksize, ksize), sigma)
    
    # GPU è·¯å¾‘
    gpu_image = cv2.cuda_GpuMat()
    gpu_image.upload(image_np)
    
    gpu_result = cv2.cuda.GaussianBlur(
        gpu_image,
        ksize=(ksize, ksize),
        sigmaX=sigma,
        borderMode=cv2.BORDER_REFLECT
    )
    
    return gpu_result.download()
```

#### ç¯„ä¾‹ 3: æ‰¹æ¬¡è™•ç†ï¼ˆStreamï¼‰

```python
def convolve_batch_opencv_cuda(images_np: list, kernel_np: np.ndarray) -> list:
    """
    æ‰¹æ¬¡å·ç©ï¼ˆä½¿ç”¨ CUDA Stream ä¸¦è¡Œï¼‰
    """
    if cv2.cuda.getCudaEnabledDeviceCount() == 0:
        return [cv2.filter2D(img, -1, kernel_np) for img in images_np]
    
    # å‰µå»º Streamï¼ˆç•°æ­¥åŸ·è¡Œï¼‰
    stream = cv2.cuda.Stream()
    
    results = []
    for img in images_np:
        gpu_image = cv2.cuda_GpuMat()
        gpu_image.upload(img, stream=stream)
        
        gpu_result = cv2.cuda.filter2D(gpu_image, -1, kernel_np, stream=stream)
        
        result = gpu_result.download(stream=stream)
        results.append(result)
    
    # ç­‰å¾…æ‰€æœ‰æ“ä½œå®Œæˆ
    stream.waitForCompletion()
    
    return results
```

---

### åŠŸèƒ½å°ç…§è¡¨

| CPU å‡½æ•¸ | GPU å‡½æ•¸ | æ”¯æ´åº¦ |
|---------|---------|--------|
| `cv2.filter2D` | `cv2.cuda.filter2D` | âœ… |
| `cv2.GaussianBlur` | `cv2.cuda.GaussianBlur` | âœ… |
| `cv2.resize` | `cv2.cuda.resize` | âœ… |
| `cv2.cvtColor` | `cv2.cuda.cvtColor` | âœ… |
| `cv2.threshold` | `cv2.cuda.threshold` | âœ… |
| `cv2.morphologyEx` | `cv2.cuda.morphologyEx` | âœ… |
| **numpy FFT** | âŒ ç„¡å°æ‡‰ | âŒ |

**ç™¼ç¾**: OpenCV CUDA ä¸æ”¯æ´ FFT å·ç©ï¼ˆåƒ…ç©ºé–“åŸŸï¼‰

---

### æ•ˆèƒ½åˆ†æ

#### é æœŸåŠ é€Ÿæ¯”ï¼ˆ2000Ã—3000 å½±åƒï¼Œ201Ã—201 æ ¸ï¼‰

| æ“ä½œ | CPU | OpenCV CUDA | åŠ é€Ÿæ¯” |
|------|-----|-------------|--------|
| **filter2D** | 250 ms | 40 ms | **6.25x** |
| **GaussianBlur** | 200 ms | 35 ms | **5.71x** |
| **æ‰¹æ¬¡ 10 å¼µ** | 2500 ms | 280 ms | **8.93x** |

**èˆ‡ CuPy å°æ¯”**: é¡ä¼¼æ•ˆèƒ½ï¼ˆ6-8xï¼‰ï¼Œä½†ç·¨è­¯éº»ç…©ã€‚

---

### æ•´åˆåˆ° Phos

#### ä¿®æ”¹ `convolve_adaptive()`

```python
# Phos_0.3.0.py

# é ‚éƒ¨æª¢æ¸¬ CUDA æ”¯æ´
OPENCV_CUDA_AVAILABLE = cv2.cuda.getCudaEnabledDeviceCount() > 0

def convolve_adaptive(image, kernel, method='auto', use_gpu=False, backend='cupy'):
    """
    è‡ªé©æ‡‰å·ç©ï¼ˆæ”¯æ´ OpenCV CUDAï¼‰
    """
    if use_gpu and backend == 'opencv_cuda' and OPENCV_CUDA_AVAILABLE:
        return convolve_opencv_cuda(image, kernel)
    elif method == 'auto':
        ksize = kernel.shape[0]
        if ksize > 150:
            return convolve_fft(image, kernel)
        else:
            return cv2.filter2D(image, -1, kernel, borderType=cv2.BORDER_REFLECT)
    # ... å…¶ä»–åˆ†æ”¯
```

---

### OpenCV CUDA å„ªç¼ºé»ç¸½çµ

#### âœ… å„ªé»

1. **ç„¡é¡å¤–ä¾è³´**: ä¸éœ€ CuPy/PyTorchï¼ˆç·¨è­¯å¾Œï¼‰
2. **API ç›¸ä¼¼**: èˆ‡ CPU ç‰ˆæœ¬å¹¾ä¹ä¸€è‡´
3. **å¤šå¾Œç«¯**: CUDA/OpenCL/Vulkanï¼ˆè·¨å¹³å°æ½›åŠ›ï¼‰
4. **Reflect æ”¯æ´**: âœ… åŸç”Ÿæ”¯æ´ `BORDER_REFLECT`
5. **è¦–è¦ºç›¸å®¹**: èˆ‡ CPU ç‰ˆæœ¬å®Œå…¨ç­‰åƒ¹

#### âŒ ç¼ºé»

1. **ç·¨è­¯è¤‡é›œ**: âŒ ç„¡é ç·¨è­¯è¼ªï¼Œéœ€æ‰‹å‹•ç·¨è­¯ï¼ˆ30-60åˆ†é˜ï¼‰
2. **æ–‡æª”ç¼ºä¹**: å®˜æ–¹æ–‡æª”å°‘ï¼Œç¯„ä¾‹æœ‰é™
3. **åŠŸèƒ½å—é™**: ç„¡ FFT å·ç©æ”¯æ´
4. **ç¶­è­·æˆæœ¬**: æ¯æ¬¡ OpenCV æ›´æ–°éœ€é‡æ–°ç·¨è­¯
5. **éŒ¯èª¤é™¤éŒ¯**: CUDA éŒ¯èª¤è¨Šæ¯ä¸å‹å–„

#### ğŸ¯ é©ç”¨å ´æ™¯

- âœ… å·²æœ‰ OpenCV CUDA ç·¨è­¯ç’°å¢ƒ
- âœ… ä¸é¡˜å¢åŠ  Python ä¾è³´
- âœ… éœ€è¦ OpenCL/Vulkan å¾Œç«¯ï¼ˆAMD GPUï¼‰
- âŒ æ–°å°ˆæ¡ˆï¼ˆç·¨è­¯æˆæœ¬å¤ªé«˜ï¼‰
- âŒ å¿«é€ŸåŸå‹é–‹ç™¼

---

## 4ï¸âƒ£ æ¡†æ¶æ©«å‘å°æ¯”

### API ç›¸å®¹æ€§å°æ¯”

| æ¡†æ¶ | NumPy ç›¸å®¹ | éœ€è½‰æ› | Reflect Padding | å­¸ç¿’æ›²ç·š |
|------|-----------|--------|-----------------|---------|
| **CuPy** | â­â­â­â­â­ | æœ€å° | âœ… | ä½ |
| **PyTorch** | â­â­â­ | 4D tensor | âš ï¸ æ‰‹å‹• pad | ä¸­ |
| **JAX** | â­â­â­â­ | æœ€å° | âŒ ä¸æ”¯æ´ | é«˜ |
| **OpenCV CUDA** | â­â­â­â­ | GpuMat | âœ… | ä½ |

### æ•ˆèƒ½å°æ¯”ï¼ˆé æ¸¬ï¼‰

| æ¡†æ¶ | å–®å¼µå½±åƒ | æ‰¹æ¬¡ 10 å¼µ | é¦–æ¬¡èª¿ç”¨ | è¨˜æ†¶é«” |
|------|---------|-----------|---------|--------|
| **CuPy** | 8-10x | 9-11x | å¿« | ä½ |
| **PyTorch** | 6-8x | 13-15x | ä¸­ | é«˜ |
| **JAX** | 12-15x | 16-18x | æ…¢ | ä¸­ |
| **OpenCV CUDA** | 6-8x | 8-10x | å¿« | ä½ |

### å®‰è£è¤‡é›œåº¦å°æ¯”

| æ¡†æ¶ | Linux | Windows | macOS | ä¾è³´å¤§å° |
|------|-------|---------|-------|---------|
| **CuPy** | â­â­â­â­â­ | â­â­â­â­â­ | âŒ | 200MB |
| **PyTorch** | â­â­â­â­â­ | â­â­â­â­â­ | â­â­â­ (MPS) | 2GB |
| **JAX** | â­â­â­â­ | â­â­ | â­ | 500MB |
| **OpenCV CUDA** | â­â­ | â­ | âŒ | 0MB (ç·¨è­¯) |

### ç”Ÿæ…‹ç³»çµ±å°æ¯”

| æ¡†æ¶ | ç¤¾ç¾¤è¦æ¨¡ | æ–‡æª”å“è³ª | æ›´æ–°é »ç‡ | æœªä¾†æ½›åŠ› |
|------|---------|---------|---------|---------|
| **CuPy** | ä¸­ | å¥½ | ç©©å®š | ä¸­ |
| **PyTorch** | å¤§ | å„ªç§€ | å¿« | é«˜ |
| **JAX** | ä¸­ | ä¸­ | å¿« | é«˜ |
| **OpenCV CUDA** | å° | å·® | æ…¢ | ä½ |

---

## 5ï¸âƒ£ å¯¦éš›æ¸¬è©¦çµæœï¼ˆTODOï¼‰

### æ¸¬è©¦ç’°å¢ƒ

```
ç¡¬é«”: NVIDIA RTX 3090 (24GB VRAM)
CPU: AMD Ryzen 9 5950X (16C/32T)
RAM: 64GB DDR4-3600
OS: Ubuntu 22.04 LTS
CUDA: 11.8
Python: 3.11
```

### æ¸¬è©¦è…³æœ¬

```python
# scripts/benchmark_gpu_frameworks.py

import time
import numpy as np
import cv2

# æ¢ä»¶å°å…¥
try:
    import cupy as cp
    CUPY_AVAILABLE = True
except:
    CUPY_AVAILABLE = False

try:
    import torch
    TORCH_AVAILABLE = torch.cuda.is_available()
except:
    TORCH_AVAILABLE = False

try:
    import jax
    JAX_AVAILABLE = len(jax.devices('gpu')) > 0
except:
    JAX_AVAILABLE = False

OPENCV_CUDA_AVAILABLE = cv2.cuda.getCudaEnabledDeviceCount() > 0

def benchmark_all_frameworks():
    """æ¸¬è©¦æ‰€æœ‰æ¡†æ¶æ•ˆèƒ½"""
    
    # æ¸¬è©¦å½±åƒ
    image = np.random.rand(2000, 3000).astype(np.float32)
    kernel = cv2.getGaussianKernel(201, 50)
    kernel = (kernel @ kernel.T).astype(np.float32)
    
    results = {}
    
    # CPU Baseline
    print("æ¸¬è©¦ CPU (OpenCV filter2D)...")
    t0 = time.perf_counter()
    for _ in range(5):
        result_cpu = cv2.filter2D(image, -1, kernel)
    results['CPU_filter2D'] = (time.perf_counter() - t0) / 5 * 1000
    
    # CPU FFT
    print("æ¸¬è©¦ CPU (FFT)...")
    # ... (å¯¦ä½œçœç•¥)
    
    # CuPy
    if CUPY_AVAILABLE:
        print("æ¸¬è©¦ CuPy...")
        # ... (å¯¦ä½œçœç•¥)
    
    # PyTorch
    if TORCH_AVAILABLE:
        print("æ¸¬è©¦ PyTorch...")
        # ... (å¯¦ä½œçœç•¥)
    
    # JAX
    if JAX_AVAILABLE:
        print("æ¸¬è©¦ JAX...")
        # ... (å¯¦ä½œçœç•¥)
    
    # OpenCV CUDA
    if OPENCV_CUDA_AVAILABLE:
        print("æ¸¬è©¦ OpenCV CUDA...")
        # ... (å¯¦ä½œçœç•¥)
    
    # è¼¸å‡ºçµæœ
    print("\n" + "="*60)
    print(f"{'æ¡†æ¶':<20} {'å¹³å‡æ™‚é–“':<12} {'åŠ é€Ÿæ¯”':<10}")
    print("="*60)
    baseline = results['CPU_filter2D']
    for name, time_ms in results.items():
        speedup = baseline / time_ms
        print(f"{name:<20} {time_ms:>10.1f}ms  {speedup:>8.2f}x")
    print("="*60)

if __name__ == '__main__':
    benchmark_all_frameworks()
```

### é æœŸçµæœï¼ˆæœªå¯¦æ¸¬ï¼‰

```
============================================================
æ¡†æ¶                  å¹³å‡æ™‚é–“      åŠ é€Ÿæ¯”       
============================================================
CPU_filter2D              380.0ms      1.00x
CPU_FFT                   250.0ms      1.52x
GPU_CuPy                   45.0ms      8.44x
GPU_PyTorch                60.0ms      6.33x
GPU_JAX                    30.0ms     12.67x  â† ç†è«–æœ€å¿«
GPU_OpenCV_CUDA            50.0ms      7.60x
============================================================
```

**æ³¨æ„**: ä»¥ä¸Šç‚ºç†è«–é æ¸¬ï¼Œå¯¦éš›éœ€æ¸¬è©¦é©—è­‰ï¼

---

## 6ï¸âƒ£ æœ€çµ‚å»ºè­°

### æ¨è–¦æ’åºï¼ˆè€ƒæ…® Phos å¯¦éš›éœ€æ±‚ï¼‰

#### ğŸ¥‡ ç¬¬ä¸€é¸æ“‡ï¼šCuPy

**ç†ç”±**:
1. âœ… NumPy API ç›¸å®¹ï¼ˆå¹¾ä¹é›¶å­¸ç¿’æˆæœ¬ï¼‰
2. âœ… æ”¯æ´ `reflect` é‚Šç•Œ
3. âœ… å®‰è£ç°¡å–®ï¼ˆ`pip install cupy-cuda11x`ï¼‰
4. âœ… æ–‡æª”å®Œå–„ï¼Œç¤¾ç¾¤æˆç†Ÿ
5. âœ… æ•ˆèƒ½å„ªç§€ï¼ˆ8-10xï¼‰

**ä½¿ç”¨å ´æ™¯**: æ‰€æœ‰ Phos ç”¨æˆ¶ï¼ˆLinux/Windows + NVIDIA GPUï¼‰

---

#### ğŸ¥ˆ ç¬¬äºŒé¸æ“‡ï¼šPyTorch

**ç†ç”±**:
1. âœ… å®‰è£æœ€ç°¡å–®ï¼ˆè‡ªå¸¶ CUDA runtimeï¼‰
2. âœ… æœªä¾†å¯æ“´å±•ï¼ˆæ·±åº¦å­¸ç¿’è† ç‰‡æ¨¡å‹ï¼‰
3. âœ… æ‰¹æ¬¡è™•ç†å„ªå‹¢æ˜é¡¯ï¼ˆ13-15xï¼‰
4. âš ï¸ API è½‰æ›æœ‰é–‹éŠ·
5. âŒ ä¾è³´é¾å¤§ï¼ˆ2GBï¼‰

**ä½¿ç”¨å ´æ™¯**: 
- è¨ˆåŠƒæ“´å±•æ·±åº¦å­¸ç¿’åŠŸèƒ½
- æ‰¹æ¬¡è™•ç†ç‚ºä¸»ï¼ˆ10+ å¼µå½±åƒï¼‰
- ä¸ä»‹æ„ä¾è³´å¤§å°

---

#### ğŸ¥‰ ç¬¬ä¸‰é¸æ“‡ï¼šJAX

**ç†ç”±**:
1. âœ… ç†è«–æ•ˆèƒ½æœ€é«˜ï¼ˆ12-15xï¼‰
2. âœ… NumPy API ç›¸ä¼¼
3. âŒ **ä¸æ”¯æ´ `reflect` é‚Šç•Œ**ï¼ˆè‡´å‘½ç¼ºé™·ï¼‰
4. âš ï¸ ç·¨è­¯é–‹éŠ·å¤§ï¼ˆé¦–æ¬¡èª¿ç”¨æ…¢ï¼‰
5. âš ï¸ ç”Ÿæ…‹è¼ƒå°

**ä½¿ç”¨å ´æ™¯**: 
- ç ”ç©¶/å¯¦é©—æ€§å°ˆæ¡ˆ
- é¡˜æ„å¦¥å”é‚Šç•Œæ¨¡å¼ï¼ˆä½¿ç”¨ `edge`ï¼‰
- Linux ç’°å¢ƒ

**çµè«–**: **ä¸æ¨è–¦ç”¨æ–¼ Phos**ï¼ˆé‚Šç•Œä¸ç›¸å®¹ï¼‰

---

#### 4ï¸âƒ£ ç¬¬å››é¸æ“‡ï¼šOpenCV CUDA

**ç†ç”±**:
1. âœ… ç„¡é¡å¤– Python ä¾è³´
2. âœ… æ”¯æ´ `reflect` é‚Šç•Œ
3. âŒ **ç·¨è­¯æ¥µè¤‡é›œ**ï¼ˆ30-60åˆ†é˜ï¼‰
4. âŒ æ–‡æª”ç¼ºä¹
5. âŒ åŠŸèƒ½å—é™ï¼ˆç„¡ FFTï¼‰

**ä½¿ç”¨å ´æ™¯**: 
- å·²æœ‰ OpenCV CUDA ç·¨è­¯ç’°å¢ƒ
- ä¸é¡˜å¢åŠ ä¾è³´
- éœ€è¦ OpenCL/Vulkanï¼ˆAMD GPUï¼‰

**çµè«–**: **åƒ…ç•¶å·²ç·¨è­¯æ™‚è€ƒæ…®**

---

### æ±ºç­–çŸ©é™£

| éœ€æ±‚ | CuPy | PyTorch | JAX | OpenCV CUDA |
|------|------|---------|-----|-------------|
| **æ˜“æ–¼å®‰è£** | âœ… | âœ… | âš ï¸ | âŒ |
| **API ç›¸å®¹** | âœ… | âš ï¸ | âœ… | âœ… |
| **Reflect æ”¯æ´** | âœ… | âš ï¸ | âŒ | âœ… |
| **å–®å¼µæ•ˆèƒ½** | âœ… | âœ… | âœ… | âœ… |
| **æ‰¹æ¬¡æ•ˆèƒ½** | âœ… | â­ | â­ | âœ… |
| **ä¾è³´å¤§å°** | âœ… | âŒ | âš ï¸ | âœ… |
| **æœªä¾†æ“´å±•** | âš ï¸ | â­ | â­ | âŒ |
| **macOS æ”¯æ´** | âŒ | âš ï¸ | âŒ | âŒ |

### å¯¦ä½œå»ºè­°

#### çŸ­æœŸï¼ˆ1-2 é€±ï¼‰

âœ… **æ¡ç”¨ CuPy**ï¼ˆå¦‚åŸè¨ˆç•«ï¼‰

**è¡Œå‹•æ¸…å–®**:
1. å¯¦ä½œ `phos_gpu.py`ï¼ˆCuPy å·ç©ï¼‰
2. æ•´åˆåˆ° `convolve_adaptive()`
3. æ¸¬è©¦ç²¾åº¦ï¼ˆPSNR >40dBï¼‰
4. æ¸¬è©¦æ•ˆèƒ½ï¼ˆç›®æ¨™ 8-10xï¼‰
5. æ·»åŠ  UI é–‹é—œ

#### ä¸­æœŸï¼ˆ1-2 æœˆï¼‰

âš ï¸ **è©•ä¼° PyTorch æ•´åˆ**ï¼ˆå¦‚è¨ˆåŠƒæ“´å±•æ·±åº¦å­¸ç¿’ï¼‰

**æ¢ä»¶**:
- æ‰¹æ¬¡è™•ç†éœ€æ±‚å¢åŠ 
- è¨ˆåŠƒé–‹ç™¼å¯è¨“ç·´æ¿¾é¡
- ç”¨æˆ¶æ¥å— 2GB ä¾è³´

#### é•·æœŸï¼ˆ3-6 æœˆï¼‰

ğŸ”¬ **å¯¦é©— JAX**ï¼ˆç ”ç©¶æ€§è³ªï¼‰

**æ¢ä»¶**:
- è§£æ±º `reflect` é‚Šç•Œå•é¡Œï¼ˆè‡ªè¡Œå¯¦ä½œï¼‰
- æ¥µè‡´æ•ˆèƒ½éœ€æ±‚ï¼ˆ>10xï¼‰
- é¡˜æ„æ‰¿æ“”ç¶­è­·æˆæœ¬

---

## 7ï¸âƒ£ å¯¦ä½œæª¢æŸ¥è¡¨

### P0 (ç«‹å³åŸ·è¡Œ)

- [x] å®Œæˆ GPU æ¡†æ¶æ¯”è¼ƒæ–‡æª”ï¼ˆæœ¬æ–‡ä»¶ï¼‰
- [ ] æ±ºç­–ï¼šç¢ºèªä½¿ç”¨ CuPyï¼ˆå¦‚åŸè¨ˆç•«ï¼‰
- [ ] å‰µå»º `phos_gpu.py`ï¼ˆCuPy å¯¦ä½œï¼‰
- [ ] æ¸¬è©¦åŸºæº–ï¼ˆ2000Ã—3000 å½±åƒï¼‰

### P1 (é‡è¦)

- [ ] å¦‚æ•ˆèƒ½ä¸è¶³ï¼šæ¸¬è©¦ PyTorchï¼ˆæ‰¹æ¬¡è™•ç†ï¼‰
- [ ] å¦‚éœ€æ“´å±•ï¼šè©•ä¼° PyTorch æ·±åº¦å­¸ç¿’æ•´åˆ
- [ ] æ–‡æª”ï¼šæ›´æ–° READMEï¼ˆGPU éœ€æ±‚èªªæ˜ï¼‰

### P2 (å¯é¸)

- [ ] å¯¦é©—ï¼šJAX é‚Šç•Œæ¨¡å¼è‡ªè¡Œå¯¦ä½œ
- [ ] å¯¦é©—ï¼šOpenCV CUDAï¼ˆå¦‚å·²æœ‰ç·¨è­¯ç’°å¢ƒï¼‰
- [ ] æ¯”è¼ƒï¼šå¤šæ¡†æ¶å¯¦æ¸¬åŸºæº–ï¼ˆRTX 3090ï¼‰

---

## 8ï¸âƒ£ åƒè€ƒè³‡æ–™

### å®˜æ–¹æ–‡æª”

1. **CuPy**: https://docs.cupy.dev/en/stable/
2. **PyTorch**: https://pytorch.org/docs/stable/
3. **JAX**: https://jax.readthedocs.io/en/latest/
4. **OpenCV CUDA**: https://docs.opencv.org/4.x/d1/dfb/intro.html

### æ•ˆèƒ½åŸºæº–

5. **GPU å·ç©å°æ¯”**: https://github.com/NVIDIA/cuda-samples
6. **PyTorch vs JAX**: https://wandb.ai/cayush/pytorch-vs-jax

### è«–æ–‡

7. **XLA ç·¨è­¯å™¨**: https://www.tensorflow.org/xla
8. **CUDA æœ€ä½³å¯¦è¸**: https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/

---

**æ–‡æª”ç‰ˆæœ¬**: v1.0  
**æœ€å¾Œæ›´æ–°**: 2025-12-20  
**ç‹€æ…‹**: âœ… å®Œæˆï¼Œå»ºè­°æ¡ç”¨ CuPy
